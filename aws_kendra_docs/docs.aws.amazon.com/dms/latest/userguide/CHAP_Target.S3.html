<!DOCTYPE html>
    <html xmlns="http://www.w3.org/1999/xhtml" lang="en-US"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8" /><title>Using Amazon S3 as a target for AWS Database Migration Service - AWS Database Migration Service</title><meta name="viewport" content="width=device-width,initial-scale=1" /><meta name="assets_root" content="/assets" /><meta name="target_state" content="CHAP_Target.S3" /><meta name="default_state" content="CHAP_Target.S3" /><link rel="icon" type="image/ico" href="/assets/images/favicon.ico" /><link rel="shortcut icon" type="image/ico" href="/assets/images/favicon.ico" /><link rel="canonical" href="https://docs.aws.amazon.com/dms/latest/userguide/CHAP_Target.S3.html" /><meta name="description" content="Use Amazon S3 as a target for data migration using AWS Database Migration Service." /><meta name="deployment_region" content="IAD" /><meta name="product" content="AWS Database Migration Service" /><meta name="guide" content="User Guide" /><meta name="abstract" content="Migrate databases to AWS easily and securely using AWS Database Migration Service (AWS DMS) with this User Guide." /><meta name="guide-locale" content="en_us" /><meta name="tocs" content="toc-contents.json" /><link rel="canonical" href="https://docs.aws.amazon.com/dms/latest/userguide/CHAP_Target.S3.html" /><link rel="alternative" href="https://docs.aws.amazon.com/id_id/dms/latest/userguide/CHAP_Target.S3.html" hreflang="id-id" /><link rel="alternative" href="https://docs.aws.amazon.com/id_id/dms/latest/userguide/CHAP_Target.S3.html" hreflang="id" /><link rel="alternative" href="https://docs.aws.amazon.com/de_de/dms/latest/userguide/CHAP_Target.S3.html" hreflang="de-de" /><link rel="alternative" href="https://docs.aws.amazon.com/de_de/dms/latest/userguide/CHAP_Target.S3.html" hreflang="de" /><link rel="alternative" href="https://docs.aws.amazon.com/dms/latest/userguide/CHAP_Target.S3.html" hreflang="en-us" /><link rel="alternative" href="https://docs.aws.amazon.com/dms/latest/userguide/CHAP_Target.S3.html" hreflang="en" /><link rel="alternative" href="https://docs.aws.amazon.com/es_es/dms/latest/userguide/CHAP_Target.S3.html" hreflang="es-es" /><link rel="alternative" href="https://docs.aws.amazon.com/es_es/dms/latest/userguide/CHAP_Target.S3.html" hreflang="es" /><link rel="alternative" href="https://docs.aws.amazon.com/fr_fr/dms/latest/userguide/CHAP_Target.S3.html" hreflang="fr-fr" /><link rel="alternative" href="https://docs.aws.amazon.com/fr_fr/dms/latest/userguide/CHAP_Target.S3.html" hreflang="fr" /><link rel="alternative" href="https://docs.aws.amazon.com/it_it/dms/latest/userguide/CHAP_Target.S3.html" hreflang="it-it" /><link rel="alternative" href="https://docs.aws.amazon.com/it_it/dms/latest/userguide/CHAP_Target.S3.html" hreflang="it" /><link rel="alternative" href="https://docs.aws.amazon.com/ja_jp/dms/latest/userguide/CHAP_Target.S3.html" hreflang="ja-jp" /><link rel="alternative" href="https://docs.aws.amazon.com/ja_jp/dms/latest/userguide/CHAP_Target.S3.html" hreflang="ja" /><link rel="alternative" href="https://docs.aws.amazon.com/ko_kr/dms/latest/userguide/CHAP_Target.S3.html" hreflang="ko-kr" /><link rel="alternative" href="https://docs.aws.amazon.com/ko_kr/dms/latest/userguide/CHAP_Target.S3.html" hreflang="ko" /><link rel="alternative" href="https://docs.aws.amazon.com/pt_br/dms/latest/userguide/CHAP_Target.S3.html" hreflang="pt-br" /><link rel="alternative" href="https://docs.aws.amazon.com/pt_br/dms/latest/userguide/CHAP_Target.S3.html" hreflang="pt" /><link rel="alternative" href="https://docs.aws.amazon.com/zh_cn/dms/latest/userguide/CHAP_Target.S3.html" hreflang="zh-cn" /><link rel="alternative" href="https://docs.aws.amazon.com/zh_tw/dms/latest/userguide/CHAP_Target.S3.html" hreflang="zh-tw" /><link rel="alternative" href="https://docs.aws.amazon.com/dms/latest/userguide/CHAP_Target.S3.html" hreflang="x-default" /><meta name="feedback-item" content="DMS" /><meta name="this_doc_product" content="AWS Database Migration Service" /><meta name="this_doc_guide" content="User Guide" /><script defer="" src="/assets/r/vendor4.js?version=2021.12.02"></script><script defer="" src="/assets/r/vendor3.js?version=2021.12.02"></script><script defer="" src="/assets/r/vendor1.js?version=2021.12.02"></script><script defer="" src="/assets/r/awsdocs-common.js?version=2021.12.02"></script><script defer="" src="/assets/r/awsdocs-doc-page.js?version=2021.12.02"></script><link href="/assets/r/vendor4.css?version=2021.12.02" rel="stylesheet" /><link href="/assets/r/awsdocs-common.css?version=2021.12.02" rel="stylesheet" /><link href="/assets/r/awsdocs-doc-page.css?version=2021.12.02" rel="stylesheet" /><script async="" id="awsc-panorama-bundle" type="text/javascript" src="https://prod.pa.cdn.uis.awsstatic.com/panorama-nav-init.js" data-config="{'appEntity':'aws-documentation','region':'us-east-1','service':'dms'}"></script><meta id="panorama-serviceSubSection" value="User Guide" /><meta id="panorama-serviceConsolePage" value="Using Amazon S3 as a target for AWS Database Migration Service" /></head><body class="awsdocs awsui"><div class="awsdocs-container"><awsdocs-header></awsdocs-header><awsui-app-layout id="app-layout" class="awsui-util-no-gutters" ng-controller="ContentController as $ctrl" header-selector="awsdocs-header" navigation-hide="false" navigation-width="$ctrl.navWidth" navigation-open="$ctrl.navOpen" navigation-change="$ctrl.onNavChange($event)" tools-hide="$ctrl.hideTools" tools-width="$ctrl.toolsWidth" tools-open="$ctrl.toolsOpen" tools-change="$ctrl.onToolsChange($event)"><div id="guide-toc" dom-region="navigation"><awsdocs-toc></awsdocs-toc></div><div id="main-column" dom-region="content" tabindex="-1"><awsdocs-view class="awsdocs-view"><div id="awsdocs-content"><head><title>Using Amazon S3 as a target for AWS Database Migration Service - AWS Database Migration Service</title><meta name="pdf" content="/pdfs/dms/latest/userguide/dms-ug.pdf#CHAP_Target.S3" /><meta name="github" content="https://github.com/awsdocs/aws-dms-user-guide/tree/main/doc_source/CHAP_Target.S3.md" /><meta name="rss" content="aws-dms-updates.rss" /><meta name="forums" content="http://forums.aws.amazon.com/forum.jspa?forumID=3" /><meta name="feedback" content="https://docs.aws.amazon.com/forms/aws-doc-feedback?hidden_service_name=DMS&amp;topic_url=http://docs.aws.amazon.com/en_us/dms/latest/userguide/CHAP_Target.S3.html" /><meta name="feedback-yes" content="feedbackyes.html?topic_url=http://docs.aws.amazon.com/en_us/dms/latest/userguide/CHAP_Target.S3.html" /><meta name="feedback-no" content="feedbackno.html?topic_url=http://docs.aws.amazon.com/en_us/dms/latest/userguide/CHAP_Target.S3.html" /><meta name="keywords" content="Amazon Database Migration Service,Amazon DMS,Importing Data to Amazon Web Services,replication instance" /><script type="application/ld+json">
{
    "@context" : "https://schema.org",
    "@type" : "BreadcrumbList",
    "itemListElement" : [
      {
        "@type" : "ListItem",
        "position" : 1,
        "name" : "AWS",
        "item" : "https://aws.amazon.com"
      },
      {
        "@type" : "ListItem",
        "position" : 2,
        "name" : "AWS Database Migration Service",
        "item" : "https://docs.aws.amazon.com/dms/index.html"
      },
      {
        "@type" : "ListItem",
        "position" : 3,
        "name" : "User Guide",
        "item" : "https://docs.aws.amazon.com/dms/latest/userguide"
      },
      {
        "@type" : "ListItem",
        "position" : 4,
        "name" : "Working with AWS DMS endpoints",
        "item" : "https://docs.aws.amazon.com/dms/latest/userguide/CHAP_Endpoints.html"
      },
      {
        "@type" : "ListItem",
        "position" : 5,
        "name" : "Targets for data migration",
        "item" : "https://docs.aws.amazon.com/dms/latest/userguide/CHAP_Target.html"
      },
      {
        "@type" : "ListItem",
        "position" : 6,
        "name" : "Using Amazon S3 as a target for AWS Database Migration Service",
        "item" : "https://docs.aws.amazon.com/dms/latest/userguide/CHAP_Target.html"
      }
    ]
}
</script></head><body><div id="main"><div style="display: none"><a href="/pdfs/dms/latest/userguide/dms-ug.pdf#CHAP_Target.S3" target="_blank" rel="noopener noreferrer" title="Open PDF"></a><a href="https://github.com/awsdocs/aws-dms-user-guide/tree/main/doc_source/CHAP_Target.S3.md" target="_blank" rel="noopener noreferrer" title="Edit this page on GitHub"></a></div><div id="breadcrumbs" class="breadcrumb"><a href="https://aws.amazon.com">AWS</a><a href="/index.html">Documentation</a><a href="/dms/index.html">AWS Database Migration Service</a><a href="Welcome.html">User Guide</a></div><div id="page-toc-src"><a href="#CHAP_Target.S3.Prerequisites">Prerequisites for using Amazon S3 as target</a><a href="#CHAP_Target.S3.Limitations">Limitations on Amazon S3 as a target</a><a href="#CHAP_Target.S3.Security">Security requirements when using Amazon S3 as target</a><a href="#CHAP_Target.S3.Parquet">Using Apache Parquet to store Amazon S3 objects</a><a href="#CHAP_Target.S3.Tagging">Tagging Amazon S3 objects</a><a href="#CHAP_Target.S3.KMSKeys">Create AWS KMS keys to encrypt Amazon S3 objects</a><a href="#CHAP_Target.S3.DatePartitioning">Using date-based folder partitioning</a><a href="#CHAP_Target.S3.ParallelLoad">Parallel load when using S3 as a target</a><a href="#CHAP_Target.S3.Configuring">Endpoint settings</a><a href="#CHAP_Target.S3.GlueCatalog">Using AWS Glue Data Catalog with an Amazon S3 target</a><a href="#CHAP_Target.S3.EndpointSettings">Using data encryption, parquet files, and CDC</a><a href="#CHAP_Target.S3.Configuring.InsertOps">Indicating source DB
                    operations in migrated S3 data</a><a href="#CHAP_Target.S3.DataTypes">Target data types for S3
                    Parquet</a></div><div id="main-content" class="awsui-util-container"><div id="main-col-body"><awsdocs-language-banner data-service="$ctrl.pageService"></awsdocs-language-banner><h1 class="topictitle" id="CHAP_Target.S3">Using Amazon S3 as a target for AWS Database Migration Service</h1><div class="awsdocs-page-header-container"><awsdocs-page-header></awsdocs-page-header><awsdocs-filter-selector id="awsdocs-filter-selector"></awsdocs-filter-selector></div><p>You can migrate data to Amazon S3 using AWS DMS from any of the supported database
            sources. When using Amazon S3 as a target in an AWS DMS task, both full load and change
            data capture (CDC) data is written to comma-separated value (.csv) format by default.
            For more compact storage and faster query options, you also have the option to have the
            data written to Apache Parquet (.parquet) format. </p><p>AWS DMS names files created during a full load using an incremental hexadecimal
            counter—for example LOAD00001.csv, LOAD00002..., LOAD00009, LOAD0000A, and so on
            for .csv files. AWS DMS names CDC files using timestamps, for example
            20141029-1134010000.csv. For each source table that contains records, AWS DMS creates 
            a folder under the specified target folder (if the source table is not empty).  AWS DMS 
            writes all full load and CDC files to the specified Amazon S3 bucket.</p><p>The parameter <code class="code">bucketFolder</code> contains the location where the .csv or
            .parquet files are stored before being uploaded to the S3 bucket. With .csv files, table
            data is stored in the following format in the S3 bucket, shown with full-load
            files.</p><pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="nohighlight"><code class="replaceable">database_schema_name</code>/<code class="replaceable">table_name</code>/LOAD00000001.csv
<code class="replaceable">database_schema_name</code>/<code class="replaceable">table_name</code>/LOAD00000002.csv
...
<code class="replaceable">database_schema_name</code>/<code class="replaceable">table_name</code>/LOAD00000009.csv
<code class="replaceable">database_schema_name</code>/<code class="replaceable">table_name</code>/LOAD0000000A.csv
<code class="replaceable">database_schema_name</code>/<code class="replaceable">table_name</code>/LOAD0000000B.csv
...<code class="replaceable">database_schema_name</code>/<code class="replaceable">table_name</code>/LOAD0000000F.csv
<code class="replaceable">database_schema_name</code>/<code class="replaceable">table_name</code>/LOAD00000010.csv
...</code></pre><p>You can specify the column delimiter, row delimiter, and other parameters using the
            extra connection attributes. For more information on the extra connection attributes,
            see <a href="#CHAP_Target.S3.Configuring">Endpoint settings when using
                    Amazon S3 as a target for AWS DMS</a> at the end of this section.</p><p>You can specify a bucket owner and prevent sniping by using the  
        <code class="code">ExpectedBucketOwner</code> Amazon S3 endpoint setting, as shown following. Then, when you 
        make a request to test a connection or perform a migration, S3 checks the account 
        ID of the bucket owner against the specified parameter.</p><pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="nohighlight">--s3-settings='<span>{</span>"ExpectedBucketOwner": "<em>AWS_Account_ID</em>"}'</code></pre><p>When you use AWS DMS to replicate data changes using a CDC task, the first column of the
            .csv or .parquet output file indicates how the row data was changed as shown for the
            following .csv file.</p><pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="nohighlight">
I,101,Smith,Bob,4-Jun-14,New York
U,101,Smith,Bob,8-Oct-15,Los Angeles
U,101,Smith,Bob,13-Mar-17,Dallas
D,101,Smith,Bob,13-Mar-17,Dallas
        </code></pre><p>For this example, suppose that there is an <code class="code">EMPLOYEE</code> table in the source
            database. AWS DMS writes data to the .csv or .parquet file, in response to the following
            events:</p><div class="itemizedlist">
             
             
             
             
        <ul class="itemizedlist"><li class="listitem">
                <p>A new employee (Bob Smith, employee ID 101) is hired on 4-Jun-14 at the New
                    York office. In the .csv or .parquet file, the <code class="code">I</code> in the first
                    column indicates that a new row was <code class="code">INSERT</code>ed into the EMPLOYEE
                    table at the source database.</p>
            </li><li class="listitem">
                <p>On 8-Oct-15, Bob transfers to the Los Angeles office. In the .csv or .parquet
                    file, the <code class="code">U</code> indicates that the corresponding row in the EMPLOYEE
                    table was <code class="code">UPDATE</code>d to reflect Bob's new office location. The rest of
                    the line reflects the row in the EMPLOYEE table as it appears after the
                        <code class="code">UPDATE</code>. </p>
            </li><li class="listitem">
                <p>On 13-Mar,17, Bob transfers again to the Dallas office. In the .csv or
                    .parquet file, the <code class="code">U</code> indicates that this row was
                        <code class="code">UPDATE</code>d again. The rest of the line reflects the row in the
                    EMPLOYEE table as it appears after the <code class="code">UPDATE</code>.</p>
            </li><li class="listitem">
                <p>After some time working in Dallas, Bob leaves the company. In the .csv or
                    .parquet file, the <code class="code">D</code> indicates that the row was
                    <code class="code">DELETE</code>d in the source table. The rest of the line reflects how the
                    row in the EMPLOYEE table appeared before it was deleted.</p>
            </li></ul></div><p>Note that by default for CDC, AWS DMS stores the row changes for each database table
            without regard to transaction order. If you want to store the row changes in CDC files
            according to transaction order, you need to use S3 endpoint settings to specify this and
            the folder path where you want the CDC transaction files to be stored on the S3 target.
            For more information, see <a href="#CHAP_Target.S3.EndpointSettings.CdcPath">Capturing data changes
                        (CDC) including transaction order on the S3 target</a>.</p><p>To control the frequency of writes to an Amazon S3 target during a data replication 
            task, you can configure the <code class="code">cdcMaxBatchInterval</code> and <code class="code">cdcMinFileSize</code> extra connection 
            attributes. This can result in better performance when analyzing the data without any 
            additional overhead operations.  For more information, see <a href="#CHAP_Target.S3.Configuring">Endpoint settings when using
                    Amazon S3 as a target for AWS DMS</a>
        </p><div class="highlights" id="inline-topiclist"><h6>Topics</h6><ul><li><a href="#CHAP_Target.S3.Prerequisites">Prerequisites for using Amazon S3 as a
                    target</a></li><li><a href="#CHAP_Target.S3.Limitations">Limitations to using Amazon S3 as a
                    target</a></li><li><a href="#CHAP_Target.S3.Security">Security</a></li><li><a href="#CHAP_Target.S3.Parquet">Using Apache Parquet to store Amazon S3
                    objects</a></li><li><a href="#CHAP_Target.S3.Tagging">Amazon S3 object tagging</a></li><li><a href="#CHAP_Target.S3.KMSKeys">Creating AWS KMS keys to encrypt Amazon S3 target
                    objects</a></li><li><a href="#CHAP_Target.S3.DatePartitioning">Using date-based folder partitioning</a></li><li><a href="#CHAP_Target.S3.ParallelLoad">Parallel load of partitioned sources when using Amazon S3
                    as a target for AWS DMS</a></li><li><a href="#CHAP_Target.S3.Configuring">Endpoint settings when using
                    Amazon S3 as a target for AWS DMS</a></li><li><a href="#CHAP_Target.S3.GlueCatalog">Using AWS Glue Data Catalog with an Amazon S3
                target for AWS DMS</a></li><li><a href="#CHAP_Target.S3.EndpointSettings">Using data encryption, parquet files, and CDC on your Amazon S3
                target</a></li><li><a href="#CHAP_Target.S3.Configuring.InsertOps">Indicating source DB
                    operations in migrated S3 data</a></li><li><a href="#CHAP_Target.S3.DataTypes">Target data types for S3
                    Parquet</a></li></ul></div>
            <h2 id="CHAP_Target.S3.Prerequisites">Prerequisites for using Amazon S3 as a
                    target</h2>
            <p>Before using Amazon S3 as a target, check that the following are true: </p>
            <div class="itemizedlist">
                 
                 
                 
                                 
            <ul class="itemizedlist"><li class="listitem">
                    <p>The S3 bucket that you're using as a target is in the same AWS Region
                        as the DMS replication instance you are using to migrate your data.</p>
                </li><li class="listitem">
                    <p>The AWS account that you use for the migration has an IAM role with write
                        and delete access to the S3 bucket you are using as a target.</p>
                </li><li class="listitem">
                    <p>This role has tagging access so you can tag any S3 objects written to the
                        target bucket.</p>
                </li><li class="listitem">
                    <p>The IAM role has DMS (dms.amazonaws.com) added as <em>trusted entity</em>. </p>
                </li></ul></div>
            <p>To set up this account access, ensure that the role assigned to the user account
                used to create the migration task has the following set of permissions.</p>
            <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class=""><span>{</span>
    "Version": "2012-10-17",
    "Statement": [
        <span>{</span>
            "Effect": "Allow",
            "Action": [
                "s3:PutObject",
                "s3:DeleteObject",
                "s3:PutObjectTagging"
            ],
            "Resource": [
                "arn:aws:s3:::buckettest2/*"
            ]
        },
        <span>{</span>
            "Effect": "Allow",
            "Action": [
                "s3:ListBucket"
            ],
            "Resource": [
                "arn:aws:s3:::buckettest2"
            ]
        }
    ]
}
</code></pre>
            <p>For prerequisites for using validation with S3 as a target, see <a href="./CHAP_Validating_S3.html#CHAP_Validating_S3_prerequisites">S3 target validation
                prerequisites</a>.</p>
         
            <h2 id="CHAP_Target.S3.Limitations">Limitations to using Amazon S3 as a
                    target</h2>

            <p>The following limitations apply when using Amazon S3 as a target:</p>
            <div class="itemizedlist">
                 
                 
                 
                 

                 
                 
                 
                 
            <ul class="itemizedlist"><li class="listitem">
                    <p>Don’t enable versioning for S3. If you need S3 versioning, use lifecycle policies to actively
                        delete old versions. Otherwise, you might encounter endpoint test connection failures because of
                        an S3 <code class="code">list-object</code> call timeout. To create a lifecycle policy for an S3 bucket, see
                        <a href="https://docs.aws.amazon.com/AmazonS3/latest/userguide/object-lifecycle-mgmt.html">
                            Managing your storage lifecycle</a>.
                        To delete a version of an S3 object, see
                        <a href="https://docs.aws.amazon.com/AmazonS3/latest/dev/DeletingObjectVersions.html">
                            Deleting object versions from a versioning-enabled bucket</a>.</p>
                </li><li class="listitem">
                    <p>A VPC-enabled (gateway VPC) S3 bucket is supported in versions 3.4.7 and higher.</p>
                </li><li class="listitem">
                    <p>The following data definition language (DDL) commands are supported for 
                        change data capture (CDC): Truncate Table, Drop Table, Create Table, Rename 
                        Table, Add Column, Drop Column, Rename Column, and Change Column Data Type.</p>
                    <div class="awsdocs-note"><div class="awsdocs-note-title"><awsui-icon name="status-info" variant="link"></awsui-icon><h6>Note</h6></div><div class="awsdocs-note-text"><p>A truncate DDL operation removes all files and corresponding table folders from an S3 bucket. 
                            You can use task settings to disable that behavior and configure the way DMS handles 
                            DDL behavior during change data capture (CDC). For more information, see 
                            <a href="./CHAP_Tasks.CustomizingTasks.TaskSettings.DDLHandling.html">Task
                        settings for change processing DDL handling</a>.</p></div></div>
                </li><li class="listitem">
                    <p>Full LOB mode is not supported.</p>
                </li><li class="listitem">
                    <p>Changes to the source table structure during full load are not supported.
                        Changes to data are supported during full load.</p>

                </li><li class="listitem">
                    <p>Multiple tasks that replicate data from the same source table to the same
                        target S3 endpoint bucket result in those tasks writing to the same file. We
                        recommend that you specify different target endpoints (buckets) if your data
                        source is from the same table.</p>
                </li><li class="listitem">
                    <p><code class="code">BatchApply</code>  is 
                        not supported for an S3 endpoint. Using Batch Apply (for example, 
                        the <code class="code">BatchApplyEnabled</code> target metadata task setting) for an S3 target might result in loss of data.</p>
                </li><li class="listitem">
                    <p>You can't use <code class="code">DatePartitionEnabled</code> or <code class="code">addColumnName</code> together with 
                        <code class="code">PreserveTransactions</code> or <code class="code">CdcPath</code>.</p>
                </li></ul></div>
            <p>For limitations for using validation with S3 as a target, see <a href="./CHAP_Validating_S3.html#CHAP_Validating_S3_limitations">Limitations for using S3 target
                validation</a>.</p>
         
            <h2 id="CHAP_Target.S3.Security">Security</h2>

            <p>To use Amazon S3 as a target, the account used for the migration must have write and
                delete access to the Amazon S3 bucket that is used as the target. Specify the Amazon
                Resource Name (ARN) of an IAM role that has the permissions required to access Amazon S3. </p>
            <p>AWS DMS supports a set of predefined grants for Amazon S3, known as canned access control
                lists (ACLs). Each canned ACL has a set of grantees and permissions that you can use
                to set permissions for the Amazon S3 bucket. You can specify a canned ACL using the
                    <code class="code">cannedAclForObjects</code> on the connection string attribute for your S3
                target endpoint. For more information about using the extra connection attribute
                    <code class="code">cannedAclForObjects</code>, see <a href="#CHAP_Target.S3.Configuring">Endpoint settings when using
                    Amazon S3 as a target for AWS DMS</a>. For more information about Amazon S3 canned ACLs, see <a href="http://docs.aws.amazon.com/AmazonS3/latest/dev/acl-overview.html#canned-acl">Canned ACL</a>.</p>
            <p>The IAM role that you use for the migration must be able to perform the
                    <code class="code">s3:PutObjectAcl</code> API operation.</p>
         
            <h2 id="CHAP_Target.S3.Parquet">Using Apache Parquet to store Amazon S3
                    objects</h2>
            <p>The comma-separated value (.csv) format is the default storage format for Amazon S3
                target objects. For more compact storage and faster queries, you can instead use Apache
                Parquet (.parquet) as the storage format.</p>
            <p>Apache Parquet is an open-source file storage format originally designed for
                Hadoop. For more information on Apache Parquet, see <a href="https://parquet.apache.org/" rel="noopener noreferrer" target="_blank"><span>https://parquet.apache.org/</span><awsui-icon class="awsdocs-link-icon" name="external"></awsui-icon></a>.</p>
            <p>To set .parquet as the storage format for your migrated S3 target objects, you can
                use the following mechanisms:</p>
            <div class="itemizedlist">
                 
                 
            <ul class="itemizedlist"><li class="listitem">
                    <p>Endpoint settings that you provide as parameters of a JSON object when you
                        create the endpoint using the AWS CLI  or the API for AWS DMS. For more
                        information, see <a href="#CHAP_Target.S3.EndpointSettings">Using data encryption, parquet files, and CDC on your Amazon S3
                target</a>.</p>
                </li><li class="listitem">
                    <p>Extra connection attributes that you provide as a semicolon-separated list
                        when you create the endpoint. For more information, see <a href="#CHAP_Target.S3.Configuring">Endpoint settings when using
                    Amazon S3 as a target for AWS DMS</a>.</p>
                </li></ul></div>
         
            <h2 id="CHAP_Target.S3.Tagging">Amazon S3 object tagging</h2>
            <p>You can tag Amazon S3 objects that a replication instance creates by specifying
                appropriate JSON objects as part of task-table mapping rules. For more information
                about requirements and options for S3 object tagging, including valid tag names, see
                    <a href="https://docs.aws.amazon.com/AmazonS3/latest/dev/object-tagging.html">Object tagging</a> in the
                    <em>Amazon Simple Storage Service User Guide</em>. For more information about table mapping
                using JSON, see <a href="./CHAP_Tasks.CustomizingTasks.TableMapping.SelectionTransformation.html">
                    Specifying table selection and transformations rules using
                    JSON</a>.</p>
            <p>You tag S3 objects created for specified tables and schemas by using one or more
                JSON objects of the <code class="code">selection</code> rule type. You then follow this
                    <code class="code">selection</code> object (or objects) by one or more JSON objects of the
                    <code class="code">post-processing</code> rule type with <code class="code">add-tag</code> action. These
                post-processing rules identify the S3 objects that you want to tag and specify the
                names and values of the tags that you want to add to these S3 objects.</p>
            <p>You can find the parameters to specify in JSON objects of the
                    <code class="code">post-processing</code> rule type in the following table.</p>
            <div class="table-container"><div class="table-contents"><table id="w350aac29c13c23c39b9"><thead>
                        <tr>
                            <th>Parameter</th>
                            <th>Possible values</th>
                            <th>Description</th>
                        </tr>
                    </thead>
                        <tr>
                            <td><code class="code">rule-type</code></td>
                            <td><code class="code">post-processing</code></td>
                            <td>
                                <p>A value that applies post-processing actions to the generated
                                    target objects. You can specify one or more post-processing
                                    rules to tag selected S3 objects.</p>
                            </td>
                        </tr>
                        <tr>
                            <td><code class="code">rule-id</code></td>
                            <td>A numeric value.</td>
                            <td>A unique numeric value to identify the
                                rule.</td>
                        </tr>
                        <tr>
                            <td><code class="code">rule-name</code></td>
                            <td>An alphanumeric value.</td>
                            <td>A unique name to identify the rule.</td>
                        </tr>
                        <tr>
                            <td><code class="code">rule-action</code></td>
                            <td><code class="code">add-tag</code></td>
                            <td>The post-processing action that you want to apply
                                to the S3 object. You can add one or more tags using a single JSON
                                post-processing object for the <code class="code">add-tag</code> action.</td>
                        </tr>
                        <tr>
                            <td><code class="code">object-locator</code></td>
                            <td>
                                <p><code class="code">schema-name</code> – The name of the table
                                    schema.</p>
                                <p><code class="code">table-name</code> – The name of the table.</p>
                            </td>
                            <td>
                                <p>The name of each schema and table to which the rule applies.
                                    You can use the "%" percent sign as a wildcard for all or part
                                    of the value of each <code class="code">object-locator</code> parameter.
                                    Thus, you can match these items:</p>
                                <div class="itemizedlist">
                                     
                                     
                                     
                                     
                                <ul class="itemizedlist"><li class="listitem">
                                        <p>A single table in a single schema</p>
                                    </li><li class="listitem">
                                        <p>A single table in some or all schemas</p>
                                    </li><li class="listitem">
                                        <p>Some or all tables in a single schema</p>
                                    </li><li class="listitem">
                                        <p>Some or all tables in some or all schemas</p>
                                    </li></ul></div>
                            </td>
                        </tr>
                        <tr>
                            <td><code class="code">tag-set</code></td>
                            <td>
                                <p><code class="code">key</code> – Any valid name for a single
                                    tag.</p>
                                <p><code class="code">value</code> – Any valid JSON value for this tag.
                                </p>
                            </td>
                            <td>
                                <p>The names and values for one or more tags that you want to set
                                    on each created S3 object that matches the specified
                                        <code class="code">object-locator</code>. You can specify up to 10
                                    key-value pairs in a single <code class="code">tag-set</code> parameter
                                    object. For more information on S3 object tagging, see <a href="https://docs.aws.amazon.com/AmazonS3/latest/dev/object-tagging.html">Object tagging</a>
                                    in the <em>Amazon Simple Storage Service User Guide</em>.</p>
                                <p>You can also specify a dynamic value for all or part of the
                                    value for both the <code class="code">key</code> and <code class="code">value</code>
                                    parameters of a tag using
                                        <code class="code">$<span>{</span><em>dyn-value</em>}</code>. Here,
                                            <code class="code">$<span>{</span><em>dyn-value</em>}</code> can be
                                    either <code class="code">$<span>{</span>schema-name}</code> or
                                    <code class="code">$<span>{</span>table-name}</code>. Thus, you can insert the name of the
                                    currently selected schema or table as the whole or any part of
                                    the parameter value.</p>
                                <div class="awsdocs-note"><div class="awsdocs-note-title"><awsui-icon name="status-info" variant="link"></awsui-icon><h6>Note</h6></div><div class="awsdocs-note-text"><div class="awsdocs-note awsdocs-important"><div class="awsdocs-note-title"><awsui-icon name="status-warning" variant="error"></awsui-icon><h6>Important</h6></div><div class="awsdocs-note-text"><p>If you insert a dynamic value for the <code class="code">key</code>
                                            parameter, you can generate tags with duplicate names
                                            for an S3 object, depending on how you use it. In this
                                            case, only one of the duplicate tag settings is added to
                                            the object. </p></div></div></div></div>
                            </td>
                        </tr>
                    </table></div></div>
            <p>When you specify multiple <code class="code">post-processing</code> rule types to tag a
                selection of S3 objects, each S3 object is tagged using only one
                    <code class="code">tag-set</code> object from one post-processing rule. The particular tag
                set used to tag a given S3 object is the one from the post-processing rule whose
                associated object locator best matches that S3 object. </p>
            <p>For example, suppose that two post-processing rules identify the same S3 object.
                Suppose also that the object locator from one rule uses wildcards and the object
                locator from the other rule uses an exact match to identify the S3 object (without
                wildcards). In this case, the tag set associated with the post-processing rule with
                the exact match is used to tag the S3 object. If multiple post-processing rules
                match a given S3 object equally well, the tag set associated with the first such
                post-processing rule is used to tag the object.</p>
            <div class="example"><h6>Example Adding static tags to an S3 object created for a single table and
                    schema</h6><div class="example-contents"><p>The following selection and post-processing rules add three tags
                        (<code class="code">tag_1</code>, <code class="code">tag_2</code>, and <code class="code">tag_3</code> with
                    corresponding static values <code class="code">value_1</code>, <code class="code">value_2</code>, and
                        <code class="code">value_3</code>) to a created S3 object. This S3 object corresponds to
                    a single table in the source named <code class="code">STOCK</code> with a schema named
                        <code class="code">aat2</code>.</p><pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class=""><span>{</span>
    "rules": [
        <span>{</span>
            "rule-type": "selection",
            "rule-id": "5",
            "rule-name": "5",
            "object-locator": <span>{</span>
                "schema-name": "aat2",
                "table-name": "STOCK"
            },
            "rule-action": "include"
        },
        <span>{</span>
            "rule-type": "post-processing",
            "rule-id": "41",
            "rule-name": "41",
            "rule-action": "add-tag",
            "object-locator": <span>{</span>
                "schema-name": "aat2",
                "table-name": "STOCK"
            },
            "tag-set": [
              <span>{</span>
                "key": "tag_1",
                "value": "value_1"
              },
              <span>{</span>
                "key": "tag_2",
                "value": "value_2"
              },
              <span>{</span>
                "key": "tag_3",
                "value": "value_3"
              }                                     
           ]
        }
    ]
}</code></pre></div></div>
            <div class="example"><h6>Example Adding static and dynamic tags to S3 objects created for multiple tables and
                    schemas</h6><div class="example-contents"><p>The following example has one selection and two post-processing rules, where
                    input from the source includes all tables and all of their schemas.</p><pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class=""><span>{</span>
    "rules": [
        <span>{</span>
            "rule-type": "selection",
            "rule-id": "1",
            "rule-name": "1",
            "object-locator": <span>{</span>
                "schema-name": "%",
                "table-name": "%"
            },
            "rule-action": "include"
        },
        <span>{</span>
            "rule-type": "post-processing",
            "rule-id": "21",
            "rule-name": "21",
            "rule-action": "add-tag",
            "object-locator": <span>{</span>
                "schema-name": "%",
                "table-name": "%",
            },
            "tag-set": [
              <span>{</span> 
                "key": "dw-schema-name",
                "value":"$<span>{</span>schema-name}"
              },
              <span>{</span>
                "key": "dw-schema-table",
                "value": "my_prefix_$<span>{</span>table-name}"
              }
            ]
        },
        <span>{</span>
            "rule-type": "post-processing",
            "rule-id": "41",
            "rule-name": "41",
            "rule-action": "add-tag",
            "object-locator": <span>{</span>
                "schema-name": "aat",
                "table-name": "ITEM",
            },
            "tag-set": [
              <span>{</span>
                "key": "tag_1",
                "value": "value_1"
              },
              <span>{</span>
                "key": "tag_2",
                "value": "value_2"
              }           ]
        }
    ]
}</code></pre><p>The first post-processing rule adds two tags (<code class="code">dw-schema-name</code> and
                        <code class="code">dw-schema-table</code>) with corresponding dynamic values
                        (<code class="code">$<span>{</span>schema-name}</code> and <code class="code">my_prefix_$<span>{</span>table-name}</code>) to
                    almost all S3 objects created in the target. The exception is the S3 object
                    identified and tagged with the second post-processing rule. Thus, each target S3
                    object identified by the wildcard object locator is created with tags that
                    identify the schema and table to which it corresponds in the source.</p><p>The second post-processing rule adds <code class="code">tag_1</code> and <code class="code">tag_2</code>
                    with corresponding static values <code class="code">value_1</code> and <code class="code">value_2</code>
                    to a created S3 object that is identified by an exact-match object locator. This
                    created S3 object thus corresponds to the single table in the source named
                        <code class="code">ITEM</code> with a schema named <code class="code">aat</code>. Because of the exact
                    match, these tags replace any tags on this object added from the first
                    post-processing rule, which matches S3 objects by wildcard only.</p></div></div>
            <div class="example"><h6>Example Adding both dynamic tag names and values to S3 objects </h6><div class="example-contents"><p>The following example has two selection rules and one post-processing rule.
                    Here, input from the source includes just the <code class="code">ITEM</code> table in either
                    the <code class="code">retail</code> or <code class="code">wholesale</code> schema.</p><pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class=""><span>{</span>
    "rules": [
        <span>{</span>
            "rule-type": "selection",
            "rule-id": "1",
            "rule-name": "1",
            "object-locator": <span>{</span>
                "schema-name": "retail",
                "table-name": "ITEM"
            },
            "rule-action": "include"
        },
        <span>{</span>
            "rule-type": "selection",
            "rule-id": "1",
            "rule-name": "1",
            "object-locator": <span>{</span>
                "schema-name": "wholesale",
                "table-name": "ITEM"
            },
            "rule-action": "include"
        },
        <span>{</span>
            "rule-type": "post-processing",
            "rule-id": "21",
            "rule-name": "21",
            "rule-action": "add-tag",
            "object-locator": <span>{</span>
                "schema-name": "%",
                "table-name": "ITEM",
            },
            "tag-set": [
              <span>{</span> 
                "key": "dw-schema-name",
                "value":"$<span>{</span>schema-name}"
              },
              <span>{</span>
                "key": "dw-schema-table",
                "value": "my_prefix_ITEM"
              },
              <span>{</span>
                "key": "$<span>{</span>schema-name}_ITEM_tag_1",
                "value": "value_1"
              },
              <span>{</span>
                "key": "$<span>{</span>schema-name}_ITEM_tag_2",
                "value": "value_2"
              }
            ]
    ]
}</code></pre><p>The tag set for the post-processing rule adds two tags
                        (<code class="code">dw-schema-name</code> and <code class="code">dw-schema-table</code>) to all S3
                    objects created for the <code class="code">ITEM</code> table in the target. The first tag has
                    the dynamic value <code class="code">"$<span>{</span>schema-name}"</code> and the second tag has a static
                    value, <code class="code">"my_prefix_ITEM"</code>. Thus, each target S3 object is created
                    with tags that identify the schema and table to which it corresponds in the
                    source. </p><p>In addition, the tag set adds two additional tags with dynamic names
                        (<code class="code">$<span>{</span>schema-name}_ITEM_tag_1</code> and
                        <code class="code">"$<span>{</span>schema-name}_ITEM_tag_2"</code>). These have the corresponding
                    static values <code class="code">value_1</code> and <code class="code">value_2</code>. Thus, these tags
                    are each named for the current schema, <code class="code">retail</code> or
                        <code class="code">wholesale</code>. You can't create a duplicate dynamic tag name
                    in this object, because each object is created for a single unique schema name.
                    The schema name is used to create an otherwise unique tag name.</p></div></div>
         
            <h2 id="CHAP_Target.S3.KMSKeys">Creating AWS KMS keys to encrypt Amazon S3 target
                    objects</h2>
            <p>You can create and use custom AWS KMS keys to encrypt your Amazon S3 target objects.
                After you create a KMS key, you can use it to encrypt objects using one of the
                following approaches when you create the S3 target endpoint:</p>
            <div class="itemizedlist">
                 
                 
            <ul class="itemizedlist"><li class="listitem">
                    <p>Use the following options for S3 target objects (with the default .csv
                        file storage format) when you run the <code class="code">create-endpoint</code> command
                        using the AWS CLI.</p>
                    <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="nohighlight">--s3-settings '<span>{</span>"ServiceAccessRoleArn": "<code class="replaceable">your-service-access-ARN</code>", 
"CsvRowDelimiter": "\n", "CsvDelimiter": ",", "BucketFolder": "<code class="replaceable">your-bucket-folder</code>", 
"BucketName": "<code class="replaceable">your-bucket-name</code>", "EncryptionMode": "SSE_KMS", 
"ServerSideEncryptionKmsKeyId": "<code class="replaceable">your-KMS-key-ARN</code>"}'</code></pre>
                    <p> Here, <code class="code"><code class="replaceable">your-KMS-key-ARN</code></code> is the
                        Amazon Resource Name (ARN) for your KMS key. For more information, see
                            <a href="#CHAP_Target.S3.EndpointSettings">Using data encryption, parquet files, and CDC on your Amazon S3
                target</a>.</p>
                </li><li class="listitem">
                    <p>Set the extra connection attribute <code class="code">encryptionMode</code> to the
                        value <code class="code">SSE_KMS</code> and the extra connection attribute
                        <code class="code">serverSideEncryptionKmsKeyId</code> to the ARN for your KMS key.
                        For more information, see <a href="#CHAP_Target.S3.Configuring">Endpoint settings when using
                    Amazon S3 as a target for AWS DMS</a>.</p>
                </li></ul></div>
            <p>To encrypt Amazon S3 target objects using a KMS key, you need an IAM role that has
                permissions to access the Amazon S3 bucket. This IAM role is then accessed in a policy
                (a key policy) attached to the encryption key that you create. You can do this in
                your IAM console by creating the following:</p>
            <div class="itemizedlist">
                 
                 
                 
            <ul class="itemizedlist"><li class="listitem">
                    <p>A policy with permissions to access the Amazon S3 bucket.</p>
                </li><li class="listitem">
                    <p>An IAM role with this policy.</p>
                </li><li class="listitem">
                    <p>A KMS key encryption key with a key policy that references this
                        role.</p>
                </li></ul></div>
            <p>The following procedures describe how to do this.</p>
            <div class="procedure"><h6>To create an IAM policy with permissions to access the Amazon S3 bucket</h6><ol><li><p>Open the IAM console at
         <a href="https://console.aws.amazon.com/iam/" rel="noopener noreferrer" target="_blank"><span>https://console.aws.amazon.com/iam/</span><awsui-icon class="awsdocs-link-icon" name="external"></awsui-icon></a>.</p></li><li>
                    <p>In the navigation pane, choose <b>Policies</b> in the
                        navigation pane. The <b>Policies</b> page opens.</p>
                </li><li>
                    <p>Choose <b>Create policy</b>. The <b>Create
                            policy</b> page opens.</p>
                </li><li>
                    <p>Choose <b>Service</b> and choose <b>S3</b>. A
                        list of action permissions appears.</p>
                </li><li>
                    <p>Choose <b>Expand all</b> to expand the list and choose the
                        following permissions at a minimum:</p>
                    <div class="itemizedlist">
                         
                         
                         
                    <ul class="itemizedlist"><li class="listitem">
                            <p><b>ListBucket</b></p>
                        </li><li class="listitem">
                            <p><b>PutObject</b></p>
                        </li><li class="listitem">
                            <p><b>DeleteObject</b></p>
                        </li></ul></div>
                    <p>Choose any other permissions you need, and then choose <b>Collapse
                            all</b> to collapse the list.</p>
                </li><li>
                    <p>Choose <b>Resources</b> to specify the resources that you
                        want to access. At a minimum, choose <b>All resources</b> to
                        provide general Amazon S3 resource access.</p>
                </li><li>
                    <p>Add any other conditions or permissions you need, then choose
                            <b>Review policy</b>. Check your results on the
                            <b>Review policy</b> page.</p>
                </li><li>
                    <p>If the settings are what you need, enter a name for the policy (for
                        example, <code class="code">DMS-S3-endpoint-access</code>), and any description, then
                        choose <b>Create policy</b>. The <b>Policies</b>
                        page opens with a message indicating that your policy has been
                        created.</p>
                </li><li>
                    <p>Search for and choose the policy name in the <b>Policies</b> list. The
                            <b>Summary</b> page appears displaying JSON for the policy
                        similar to the following.</p>
                    <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class=""><span>{</span>
    "Version": "2012-10-17",
    "Statement": [
        <span>{</span>
            "Sid": "VisualEditor0",
            "Effect": "Allow",
            "Action": [
                "s3:PutObject",
                "s3:ListBucket",
                "s3:DeleteObject"
            ],
            "Resource": "*"
        }
    ]
}</code></pre>
                </li></ol></div>
            <p>You have now created the new policy to access Amazon S3 resources for encryption with a
                specified name, for example <code class="code">DMS-S3-endpoint-access</code>.</p>
            <div class="procedure"><h6>To create an IAM role with this policy</h6><ol><li>
                    <p>On your IAM console, choose <b>Roles</b> in the navigation
                        pane. The <b>Roles</b> detail page opens.</p>
                </li><li>
                    <p>Choose <b>Create role</b>. The <b>Create
                            role</b> page opens.</p>
                </li><li>
                    <p>With AWS service selected as the trusted entity, choose
                            <b>DMS</b> as the service to use the IAM role.</p>
                </li><li>
                    <p>Choose <b>Next: Permissions</b>. The <b>Attach
                            permissions policies</b> view appears in the <b>Create
                            role</b> page.</p>
                </li><li>
                    <p>Find and select the IAM policy for the IAM role that you created in the
                        previous procedure (<code class="code">DMS-S3-endpoint-access</code>).</p>
                </li><li>
                    <p>Choose <b>Next: Tags</b>. The <b>Add tags</b>
                        view appears in the <b>Create role</b> page. Here, you can add
                        any tags you want.</p>
                </li><li>
                    <p>Choose <b>Next: Review</b>. The <b>Review</b>
                        view appears in the <b>Create role</b> page. Here, you can
                        verify the results.</p>
                </li><li>
                    <p>If the settings are what you need, enter a name for the role (required,
                        for example, <code class="code">DMS-S3-endpoint-access-role</code>), and any additional
                        description, then choose <b>Create role</b>. The
                            <b>Roles</b> detail page opens with a message indicating
                        that your role has been created.</p>
                </li></ol></div>
            <p>You have now created the new role to access Amazon S3 resources for encryption with a
                specified name, for example, <code class="code">DMS-S3-endpoint-access-role</code>.</p>
            <div class="procedure"><h6>To create a KMS key encryption key with a key policy that references your
                    IAM role</h6><div class="awsdocs-note"><div class="awsdocs-note-title"><awsui-icon name="status-info" variant="link"></awsui-icon><h6>Note</h6></div><div class="awsdocs-note-text"><p>For more information about how AWS DMS works with AWS KMS encryption keys, see
                            <a href="./CHAP_Security.html#CHAP_Security.EncryptionKey">Setting an encryption key and
                specifying AWS KMS permissions</a>.</p></div></div><ol><li>
     <p>Sign in to the AWS Management Console and open the AWS Key Management Service (AWS KMS) console at <a href="https://console.aws.amazon.com/kms" rel="noopener noreferrer" target="_blank"><span>https://console.aws.amazon.com/kms</span><awsui-icon class="awsdocs-link-icon" name="external"></awsui-icon></a>.</p>
    </li><li>
     <p>To change the AWS Region, use the Region selector in the upper-right corner of the page.</p>
    </li><li>
                    <p>In the navigation pane, choose <b>Customer managed keys</b>.</p>
                </li><li>
                    <p>Choose <b>Create key</b>. The <b>Configure
                            key</b> page opens.</p>
                </li><li>
                    <p>For <b>Key type</b>, choose
                        <b>Symmetric</b>.</p>
                    <div class="awsdocs-note"><div class="awsdocs-note-title"><awsui-icon name="status-info" variant="link"></awsui-icon><h6>Note</h6></div><div class="awsdocs-note-text"><p>When you create this key, you can only create a symmetric key, because
                            all AWS services, such as Amazon S3, only work with symmetric encryption
                            keys.</p></div></div>
                </li><li>
                    <p>Choose <b>Advanced Options</b>. For <b>Key material
                            origin</b>, make sure that <b>KMS</b> is chosen,
                        then choose <b>Next</b>. The <b>Add labels</b>
                        page opens.</p>
                </li><li>
                    <p>For <b>Create alias and description</b>, enter an alias for
                        the key (for example, <code class="code">DMS-S3-endpoint-encryption-key</code>) and any
                        additional description.</p>
                </li><li>
                    <p>For <b>Tags</b>, add any tags that you want to help identify
                        the key and track its usage, then choose <b>Next</b>. The
                            <b>Define key administrative permissions</b> page opens
                        showing a list of users and roles that you can choose from.</p>
                </li><li>
                    <p>Add the users and roles that you want to manage the key. Make sure that
                        these users and roles have the required permissions to manage the key. </p>
                </li><li>
                    <p>For <b>Key deletion</b>, choose whether key
                        administrators can delete the key, then choose <b>Next</b>.
                        The <b>Define key usage permissions</b> page opens showing an
                        additional list of users and roles that you can choose from.</p>                    
                </li><li>
                    <p>For <b>This account</b>, choose the available users you want
                        to perform cryptographic operations on Amazon S3 targets. Also choose the role
                        that you previously created in <b>Roles</b> to enable access
                        to encrypt Amazon S3 target objects, for example
                            <code class="code">DMS-S3-endpoint-access-role</code>).</p>
                </li><li>
                    <p>If you want to add other accounts not listed to have this same access, for
                            <b>Other AWS accounts</b>, choose <b>Add another
                            AWS account</b>, then choose <b>Next</b>. The
                            <b>Review and edit key policy</b> page opens, showing the
                        JSON for the key policy that you can review and edit by typing into the
                        existing JSON. Here, you can see where the key policy references the role
                        and users (for example, <code class="code">Admin</code> and <code class="code">User1</code>) that you
                        chose in the previous step. You can also see the different key actions
                        permitted for the different principals (users and roles), as shown in the
                        example following.</p>
                    <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class=""><span>{</span>
  "Id": "key-consolepolicy-3",
  "Version": "2012-10-17",
  "Statement": [
    <span>{</span>
      "Sid": "Enable IAM User Permissions",
      "Effect": "Allow",
      "Principal": <span>{</span>
        "AWS": [
          "arn:aws:iam::111122223333:root"
        ]
      },
      "Action": "kms:*",
      "Resource": "*"
    },
    <span>{</span>
      "Sid": "Allow access for Key Administrators",
      "Effect": "Allow",
      "Principal": <span>{</span>
        "AWS": [
          "arn:aws:iam::111122223333:role/Admin"
        ]
      },
      "Action": [
        "kms:Create*",
        "kms:Describe*",
        "kms:Enable*",
        "kms:List*",
        "kms:Put*",
        "kms:Update*",
        "kms:Revoke*",
        "kms:Disable*",
        "kms:Get*",
        "kms:Delete*",
        "kms:TagResource",
        "kms:UntagResource",
        "kms:ScheduleKeyDeletion",
        "kms:CancelKeyDeletion"
      ],
      "Resource": "*"
    },
    <span>{</span>
      "Sid": "Allow use of the key",
      "Effect": "Allow",
      "Principal": <span>{</span>
        "AWS": [
          "arn:aws:iam::111122223333:role/DMS-S3-endpoint-access-role",
          "arn:aws:iam::111122223333:role/Admin",
          "arn:aws:iam::111122223333:role/User1"
        ]
      },
      "Action": [
        "kms:Encrypt",
        "kms:Decrypt",
        "kms:ReEncrypt*",
        "kms:GenerateDataKey*",
        "kms:DescribeKey"
      ],
      "Resource": "*"
    },
    <span>{</span>
      "Sid": "Allow attachment of persistent resources",
      "Effect": "Allow",
      "Principal": <span>{</span>
        "AWS": [
          "arn:aws:iam::111122223333:role/DMS-S3-endpoint-access-role",
          "arn:aws:iam::111122223333:role/Admin",
          "arn:aws:iam::111122223333:role/User1"
        ]
      },
      "Action": [
        "kms:CreateGrant",
        "kms:ListGrants",
        "kms:RevokeGrant"
      ],
      "Resource": "*",
      "Condition": <span>{</span>
        "Bool": <span>{</span>
          "kms:GrantIsForAWSResource": true
        }
      }
    }
  ]</code></pre>
                </li><li>
                    <p>Choose <b>Finish</b>. The <b>Encryption
                            keys</b> page opens with a message indicating that your
                        KMS key has been created.</p>
                </li></ol></div>
            <p>You have now created a new KMS key with a specified alias (for example,
                    <code class="code">DMS-S3-endpoint-encryption-key</code>). This key enables AWS DMS to
                encrypt Amazon S3 target objects.</p>
         
            <h2 id="CHAP_Target.S3.DatePartitioning">Using date-based folder partitioning</h2>
            <p>AWS DMS supports S3 folder partitions based on a transaction commit date when you
                use Amazon S3 as your target endpoint. Using date-based folder partitioning, you can
                write data from a single source table to a time-hierarchy folder structure in an S3
                bucket. By partitioning folders when creating an S3 target endpoint, you can do the
                following:</p>
            <div class="itemizedlist">
                 
                                 
                 
            <ul class="itemizedlist"><li class="listitem">
                    <p>Better manage your S3 objects</p>
                </li><li class="listitem">
                    <p>Limit the size of each S3 folder</p>
                </li><li class="listitem">
                    <p>Optimize data lake queries or other subsequent operations</p>
                </li></ul></div>
            <p>You can enable date-based folder partitioning when you create an S3 target
                endpoint. You can enable it when you either migrate existing data and replicate
                ongoing changes (full load + CDC), or replicate data changes only (CDC only). Use
                the following target endpoint settings:</p>
            <div class="itemizedlist">
                 
                 
                                 
            <ul class="itemizedlist"><li class="listitem">
                    <p><code class="code">DatePartitionEnabled</code> – Specifies partitioning based on
                        dates. Set this Boolean option to <code class="code">true</code> to partition S3 bucket
                        folders based on transaction commit dates. </p>
                    <p>You can't use this setting with
                        <code class="code">PreserveTransactions</code> or <code class="code">CdcPath</code>.</p>
                    <p>The default value is <code class="code">false</code>. </p>
                </li><li class="listitem">
                    <p><code class="code">DatePartitionSequence</code> – Identifies the sequence of the
                        date format to use during folder partitioning. Set this ENUM option to
                            <code class="code">YYYYMMDD</code>, <code class="code">YYYYMMDDHH</code>, <code class="code">YYYYMM</code>,
                            <code class="code">MMYYYYDD</code>, or <code class="code">DDMMYYYY</code>. The default value is
                            <code class="code">YYYYMMDD</code>. Use this setting when
                            <code class="code">DatePartitionEnabled</code> is set to <code class="code">true.</code></p>
                </li><li class="listitem">
                    <p><code class="code">DatePartitionDelimiter</code> – Specifies a date separation
                        delimiter to use during folder partitioning. Set this ENUM option to
                            <code class="code">SLASH</code>, <code class="code">DASH</code>, <code class="code">UNDERSCORE</code>, or
                            <code class="code">NONE</code>. The default value is <code class="code">SLASH</code>. Use this
                        setting when <code class="code">DatePartitionEnabled</code> is set to
                        <code class="code">true</code>.</p>
                </li></ul></div>
            <p>The following example shows how to enable date-based folder partitioning, with
                default values for the data partition sequence and the delimiter. It uses the
                    <code class="code">--s3-settings '<span>{</span><code class="replaceable">json-settings</code>}'</code> option
                of the AWS CLI.<code class="code">create-endpoint</code> command. </p>
            <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="">
   --s3-settings '<span>{</span>"DatePartitionEnabled": true,"DatePartitionSequence": "YYYYMMDD","DatePartitionDelimiter": "SLASH"}'
            </code></pre>          
         
            <h2 id="CHAP_Target.S3.ParallelLoad">Parallel load of partitioned sources when using Amazon S3
                    as a target for AWS DMS</h2>
            <p>You can configure a parallel full load of partitioned data sources to Amazon S3
                targets. This approach improves the load times for migrating partitioned data from
                supported source database engines to the S3 target. To improve the load times of
                partitioned source data, you create S3 target subfolders mapped to the partitions of
                every table in the source database. These partition-bound subfolders allow AWS DMS to
                run parallel processes to populate each subfolder on the target.</p>
            <p>To configure a parallel full load of an S3 target, S3 supports three <code class="code">parallel-load</code> rule types
                for the <code class="code">table-settings</code> rule of table mapping:</p>
            <div class="itemizedlist">
                 
                 
                 
            <ul class="itemizedlist"><li class="listitem"><p><code class="code">partitions-auto</code></p></li><li class="listitem"><p><code class="code">partitions-list</code></p></li><li class="listitem"><p><code class="code">ranges</code></p></li></ul></div>
            <p>For more information on these parallel-load rule types, see <a href="./CHAP_Tasks.CustomizingTasks.TableMapping.SelectionTransformation.Tablesettings.html">Table and collection settings rules and operations</a>.</p>
            <p>For the <code class="code">partitions-auto</code> and <code class="code">partitions-list</code> rule types,
                AWS DMS uses each partition name from the source endpoint to identify the target
                subfolder structure, as follows.</p>
            <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="nohighlight"><code class="replaceable">bucket_name</code>/<code class="replaceable">bucket_folder</code>/<code class="replaceable">database_schema_name</code>/<code class="replaceable">table_name</code>/<code class="replaceable">partition_name</code>/LOAD<code class="replaceable">seq_num</code>.csv</code></pre>
            <p>Here, the subfolder path where data is migrated and stored on the S3 target
                includes an additional <code class="code"><code class="replaceable">partition_name</code></code>
                subfolder that corresponds to a source partition with the same name. This
                        <code class="code"><code class="replaceable">partition_name</code></code> subfolder then stores
                one or more <code>LOAD<code class="replaceable">seq_num</code>.csv</code> files
                containing data migrated from the specified source partition. Here,
                        <code class="code"><code class="replaceable">seq_num</code></code> is the sequence number
                postfix on the .csv file name, such as <code>00000001</code> in the .csv
                file with the name, <code>LOAD00000001.csv</code>.</p>
            <p>However, some database engines, such as MongoDB and DocumentDB, don't have the
                concept of partitions. For these database engines, AWS DMS adds the running source
                segment index as a prefix to the target .csv file name, as follows.</p>
            <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="nohighlight">.../<code class="replaceable">database_schema_name</code>/<code class="replaceable">table_name</code>/SEGMENT1_LOAD00000001.csv
.../<code class="replaceable">database_schema_name</code>/<code class="replaceable">table_name</code>/SEGMENT1_LOAD00000002.csv
...
.../<code class="replaceable">database_schema_name</code>/<code class="replaceable">table_name</code>/SEGMENT2_LOAD00000009.csv
.../<code class="replaceable">database_schema_name</code>/<code class="replaceable">table_name</code>/SEGMENT3_LOAD0000000A.csv</code></pre>
            <p>Here, the files <code>SEGMENT1_LOAD00000001.csv</code> and
                    <code>SEGMENT1_LOAD00000002.csv</code> are named with the same running
                source segment index prefix, <code>SEGMENT1</code>. They're named as so
                because the migrated source data for these two .csv files is associated with the
                same running source segment index. On the other hand, the migrated data stored in
                each of the target <code>SEGMENT2_LOAD00000009.csv</code> and
                    <code>SEGMENT3_LOAD0000000A.csv</code> files is associated with
                different running source segment indexes. Each file has its file name prefixed with
                the name of its running segment index, <code>SEGMENT2</code> and
                    <code>SEGMENT3</code>.</p>
            <p>For the <code class="code">ranges</code> parallel-load type, you define the column names and
                column values using the <code>columns</code> and <code class="code">boundaries</code>
                settings of the <code class="code">table-settings</code> rules. With these rules, you can specify
                partitions corresponding to segment names, as follows.</p>
            <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="">"parallel-load": <span>{</span>
    "type": "ranges",
    "columns": [
         "region",
         "sale"
    ],
    "boundaries": [
          [
               "NORTH",
               "1000"
          ],
          [
               "WEST",
               "3000"
          ]
    ],
    "segment-names": [
          "custom_segment1",
          "custom_segment2",
          "custom_segment3"
    ]
}</code></pre>
            <p>Here, the <code class="code">segment-names</code> setting defines names for three partitions to
                migrate data in parallel on the S3 target. The migrated data is parallel-loaded and
                stored in .csv files under the partition subfolders in order, as follows.</p>
            <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="nohighlight">.../<code class="replaceable">database_schema_name</code>/<code class="replaceable">table_name</code>/custom_segment1/LOAD[00000001...].csv
.../<code class="replaceable">database_schema_name</code>/<code class="replaceable">table_name</code>/custom_segment2/LOAD[00000001...].csv
.../<code class="replaceable">database_schema_name</code>/<code class="replaceable">table_name</code>/custom_segment3/LOAD[00000001...].csv</code></pre>
            <p>Here, AWS DMS stores a series of .csv files in each of the three partition
                subfolders. The series of .csv files in each partition subfolder is named
                incrementally starting from <code>LOAD00000001.csv</code> until all the data
                is migrated.</p>
            <p>In some cases, you might not explicitly name partition subfolders for a
                    <code class="code">ranges</code> parallel-load type using the <code class="code">segment-names</code>
                setting. In these case, AWS DMS applies the default of creating each series of .csv
                files under its <code class="code"><code class="replaceable">table_name</code></code> subfolder. Here,
                AWS DMS prefixes the file names of each series of .csv files with the name of the
                running source segment index, as follows.</p>
            <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="nohighlight">.../<code class="replaceable">database_schema_name</code>/<code class="replaceable">table_name</code>/SEGMENT1_LOAD[00000001...].csv
.../<code class="replaceable">database_schema_name</code>/<code class="replaceable">table_name</code>/SEGMENT2_LOAD[00000001...].csv
.../<code class="replaceable">database_schema_name</code>/<code class="replaceable">table_name</code>/SEGMENT3_LOAD[00000001...].csv
...
.../<code class="replaceable">database_schema_name</code>/<code class="replaceable">table_name</code>/SEGMENT<code class="replaceable">Z</code>_LOAD[00000001...].csv</code></pre>
         
            <h2 id="CHAP_Target.S3.Configuring">Endpoint settings when using
                    Amazon S3 as a target for AWS DMS</h2>

            <p>You can use endpoint settings to configure your Amazon S3 target database similar to using
                extra connection attributes. You specify the settings when you create the target
                endpoint using the AWS DMS console, or by using the <code class="code">create-endpoint</code> command in the 
                <a href="https://docs.aws.amazon.com/cli/latest/reference/dms/index.html">AWS CLI</a>, with the 
                <code class="code">--s3-settings '<span>{</span>"<code class="replaceable">EndpointSetting"</code>:
                    <code class="replaceable">"value"</code>, <code class="replaceable">...</code>}'</code> JSON syntax.</p> 
                       
            <p>The following table shows the endpoint settings that you can use with Amazon S3 as a target.</p>

            <div class="table-container"><div class="table-contents"><table id="w350aac29c13c23c47b7"><thead>
                        <tr>
                            <th><b>Option</b></th>
                            <th><b>Description</b></th>
                        </tr>
                    </thead>
                        <tr>
                            <td><code class="code">CsvNullValue</code></td>
                            <td>
                                <p>An optional parameter that specifies how AWS DMS treats null
                                    values. While handling the null value, you can use this
                                    parameter to pass a user-defined string as null when writing to
                                    the target. For example, when target columns are not nullable,
                                    you can use this option to differentiate between the empty
                                    string value and the null value. So, if you set this parameter
                                    value to the empty string (" " or ''), AWS DMS treats the empty
                                    string as the null value instead of <code class="code">NULL</code>.</p>
                                <p>Default value: <code class="code">NULL</code></p>
                                <p>Valid values: any valid string</p>
                                <p>Example: <code class="code">--s3-settings '<span>{</span>"CsvNullValue": " "}'</code></p>
                            </td>
                        </tr>
                        <tr>
                            <td><code class="code">AddColumnName</code></td>
                            <td>
                                <p>An optional parameter that when set to <code class="code">true</code> or
                                        <code class="code">y</code> you can use to add column name information to
                                    the .csv output file.</p>
                                    
                                <p>You can't use this parameter with
                                    <code class="code">PreserveTransactions</code> or <code class="code">CdcPath</code>.</p>
                                
                                <p>Default value: <code class="code">false</code></p>
                                <p>Valid values: <code class="code">true</code>, <code class="code">false</code>,
                                        <code class="code">y</code>, <code class="code">n</code></p>
                                <p>Example: <code class="code">--s3-settings '<span>{</span>"AddColumnName": true}'</code></p>                                
                            </td>
                        </tr>
                        <tr>
                            <td><code class="code">AddTrailingPaddingCharacter</code></td>
                            <td>
                                <p>Use the S3 target endpoint setting <code class="code">AddTrailingPaddingCharacter</code> to add 
                                    padding on string data. The default value is <code class="code">false</code>.</p>
                                <p>Type: Boolean</p>
                                <p>Example: <code class="code">--s3-settings '<span>{</span>"AddTrailingPaddingCharacter": true}'</code></p>
                            </td>
                        </tr>

                        <tr>
                            <td><code class="code">BucketFolder</code></td>
                            <td>
                                <p>An optional parameter to set a folder name in the S3 bucket.
                                    If provided, target objects are created as .csv or .parquet
                                    files in the path
                                            <code class="code"><code class="replaceable">BucketFolder</code>/<code class="replaceable">schema_name</code>/<code class="replaceable">table_name</code>/</code>.
                                    If this parameter isn't specified, then the path used is
                                            <code class="code"><code class="replaceable">schema_name</code>/<code class="replaceable">table_name</code>/</code>. </p>
                                <p>Example: <code class="code">--s3-settings '<span>{</span>"BucketFolder": "testFolder"}'</code></p>                                
                            </td>
                        </tr>
                        <tr>
                            <td><code class="code">BucketName</code></td>
                            <td>
                                <p>The name of the S3 bucket where S3 target objects are created
                                    as .csv or .parquet files.</p>
                                <p>Example: <code class="code">--s3-settings '<span>{</span>"BucketName": "buckettest"}'</code></p>                                
                            </td>
                        </tr>
                        <tr>
                            <td><code class="code">CannedAclForObjects</code></td>
                            <td>
                                <p>A value that enables AWS DMS to specify a predefined (canned)
                                    access control list for objects created in the S3 bucket as .csv
                                    or .parquet files. For more information about Amazon S3 canned ACLs,
                                    see <a href="http://docs.aws.amazon.com/AmazonS3/latest/dev/acl-overview.html#canned-acl">Canned ACL</a> in the <em>Amazon S3
                                        Developer Guide.</em></p>
                                <p>Default value: NONE</p>
                                <p>Valid values for this attribute are: NONE; PRIVATE;
                                    PUBLIC_READ; PUBLIC_READ_WRITE; AUTHENTICATED_READ;
                                    AWS_EXEC_READ; BUCKET_OWNER_READ;
                                    BUCKET_OWNER_FULL_CONTROL.</p>
                                <p>Example: <code class="code">--s3-settings '<span>{</span>"CannedAclForObjects": "PUBLIC_READ"}'</code></p>                                                                
                            </td>
                        </tr>
                        <tr>
                            <td><code class="code">CdcInsertsOnly</code></td>
                            <td>
                                <p>An optional parameter during a change data capture (CDC) load
                                    to write only INSERT operations to the comma-separated value
                                    (.csv) or columnar storage (.parquet) output files. By default
                                    (the <code class="code">false</code> setting), the first field in a .csv or
                                    .parquet record contains the letter I (INSERT), U (UPDATE), or D
                                    (DELETE). This letter indicates whether the row was inserted,
                                    updated, or deleted at the source database for a CDC load to the
                                    target. If <code class="code">cdcInsertsOnly</code> is set to
                                        <code class="code">true</code> or <code class="code">y</code>, only INSERTs from the
                                    source database are migrated to the .csv or .parquet
                                    file.</p>
                                <p>For .csv format only, how these INSERTS are recorded depends
                                    on the value of <code class="code">IncludeOpForFullLoad</code>. If
                                        <code class="code">IncludeOpForFullLoad</code> is set to
                                        <code class="code">true</code>, the first field of every CDC record is
                                    set to I to indicate the INSERT operation at the source. If
                                        <code class="code">IncludeOpForFullLoad</code> is set to
                                        <code class="code">false</code>, every CDC record is written without a
                                    first field to indicate the INSERT operation at the source. For
                                    more information about how these parameters work together, see
                                        <a href="#CHAP_Target.S3.Configuring.InsertOps">Indicating source DB
                    operations in migrated S3 data</a>.</p>
                                <p>Default value: <code class="code">false</code></p>
                                <p>Valid values: <code class="code">true</code>, <code class="code">false</code>,
                                        <code class="code">y</code>, <code class="code">n</code></p>
                                <p>Example: <code class="code">--s3-settings '<span>{</span>"CdcInsertsOnly": true}'</code></p>                                                                                                
                            </td>
                        </tr>
                        <tr>
                            <td><code class="code">CdcInsertsAndUpdates</code></td>
                            <td>
                                <p>Enables a change data capture (CDC) load to write INSERT 
                                    and UPDATE operations to .csv or .parquet (columnar storage) 
                                    output files. The default setting is <code class="code">false</code>, but when 
                                    <code class="code">cdcInsertsAndUpdates</code> is set to <code class="code">true</code> 
                                    or <code class="code">y</code>, INSERTs and UPDATEs from the source database 
                                    are migrated to the .csv or .parquet file. </p>
                                <p>For .csv file format only, how these INSERTs and 
                                    UPDATEs are recorded depends on the value of the 
                                    <code class="code">includeOpForFullLoad</code> parameter. If 
                                    <code class="code">includeOpForFullLoad</code> is set to <code class="code">true</code>, the 
                                    first field of every CDC record is set to either 
                                    <code class="code">I</code> or <code class="code">U</code> to indicate INSERT and UPDATE 
                                    operations at the source. But if <code class="code">includeOpForFullLoad</code>
                                    is set to <code class="code">false</code>, CDC records are written 
                                    without an indication of INSERT or UPDATE operations 
                                    at the source. </p>
                                <p>                                   
                                    For more information about how these parameters work together, see
                                    <a href="#CHAP_Target.S3.Configuring.InsertOps">Indicating source DB
                    operations in migrated S3 data</a>.</p>
                                <div class="awsdocs-note"><div class="awsdocs-note-title"><awsui-icon name="status-info" variant="link"></awsui-icon><h6>Note</h6></div><div class="awsdocs-note-text"><p><code class="code">CdcInsertsOnly</code> and <code class="code">cdcInsertsAndUpdates</code> 
                                        can't both be set to true for the same endpoint. Set either 
                                        <code class="code">cdcInsertsOnly</code> or <code class="code">cdcInsertsAndUpdates</code> to 
                                        <code class="code">true</code> for the same endpoint, but not both. </p></div></div>
                                <p>Default value: <code class="code">false</code></p>
                                <p>Valid values: <code class="code">true</code>, <code class="code">false</code>,
                                    <code class="code">y</code>, <code class="code">n</code></p>
                                <p>Example: <code class="code">--s3-settings '<span>{</span>"CdcInsertsAndUpdates": true}'</code></p>
                            </td>
                        </tr>
                        <tr>
                            <td>
                                <p><code class="code">CdcPath</code></p>
                            </td>
                            <td>
                                <p>Specifies the folder path of CDC files. For an S3 source, this setting is required if a 
                                    task captures change data; otherwise, it's optional. If <code class="code">CdcPath</code> is set, DMS reads 
                                    CDC files from this path and replicates the data changes to the target endpoint. For an 
                                    S3 target if you set <code class="code">PreserveTransactions</code> to true, DMS verifies that you have set 
                                    this parameter to a folder path on your S3 target where DMS can save the 
                                    transaction order for the CDC load. DMS creates this CDC folder path in either 
                                    your S3 target working directory or the S3 target location specified by <code class="code">BucketFolder</code> 
                                    and <code class="code">BucketName</code>.</p>
                                <p>You can't use this parameter with <code class="code">DatePartitionEnabled</code> or 
                                    <code class="code">AddColumnName</code>.</p>
                                <p>Type:  String</p>                                
                                <p>For example, if you specify <code class="code">CdcPath</code> as <code class="code">MyChangedData</code>, and you specify 
                                    <code class="code">BucketName</code> as <code class="code">MyTargetBucket</code> but do not specify <code class="code">BucketFolder</code>, DMS 
                                    creates the following CDC folder path: <code class="code">MyTargetBucket/MyChangedData</code>. </p>
                                <p>If you specify the same <code class="code">CdcPath</code>, and you specify <code class="code">BucketName</code> as <code class="code">MyTargetBucket</code> 
                                    and <code class="code">BucketFolder</code> as <code class="code">MyTargetData</code>, DMS creates the following CDC folder path: 
                                    <code class="code">MyTargetBucket/MyTargetData/MyChangedData</code>.</p>
                                <div class="awsdocs-note"><div class="awsdocs-note-title"><awsui-icon name="status-info" variant="link"></awsui-icon><h6>Note</h6></div><div class="awsdocs-note-text"><p>This setting is supported in AWS DMS versions 3.4.2 and higher.</p><p>When capturing data changes in transaction order, DMS always stores the row changes in .csv files 
                                            regardless of the value of the DataFormat S3 setting on the target. DMS doesn't save data changes in 
                                            transaction order using .parquet files.</p></div></div>
                            </td>
                        </tr>
                        <tr>
                            <td>
                                <p><code class="code">CdcMaxBatchInterval</code></p>
                            </td>
                            <td>
                                <p>Maximum interval length condition, defined in seconds, to output a file to Amazon S3.</p>
                                <p>Default Value:  60 seconds</p>
                                <p>When <code class="code">CdcMaxBatchInterval</code> is specified and
                                    <code class="code">CdcMinFileSize</code> is specified, the file write is
                                triggered by whichever parameter condition is met first.</p>
                            </td>
                        </tr>
                        <tr>
                            <td>
                                <p><code class="code">CdcMinFileSize</code></p>
                            </td>
                            <td>
                                <p>Minimum file size condition as defined in kilobytes to output a file to Amazon S3.</p>
                                <p>Default Value:  32000 KB</p>
                                <p>When <code class="code">CdcMinFileSize</code> is specified and
                                    <code class="code">CdcMaxBatchInterval</code> is specified, the file write is
                                triggered by whichever parameter condition is met first.</p>
                            </td>
                        </tr>
                        <tr>
                            <td>
                                <p><code class="code">PreserveTransactions</code></p>
                            </td>
                            <td>
                                <p>If set to <code class="code">true</code>, DMS saves the transaction order for change data capture (CDC) 
                                    on the Amazon S3 target specified by <code class="code">CdcPath</code>.</p>
                                <p>You can't use this parameter with <code class="code">DatePartitionEnabled</code> or 
                                    <code class="code">AddColumnName</code>.</p>
                                <p>Type:  Boolean</p>
                                <p>When capturing data changes in transaction order, DMS always stores the row changes in .csv files 
                                    regardless of the value of the DataFormat S3 setting on the target. DMS doesn't save data changes in 
                                    transaction order using .parquet files.</p>
                                <div class="awsdocs-note"><div class="awsdocs-note-title"><awsui-icon name="status-info" variant="link"></awsui-icon><h6>Note</h6></div><div class="awsdocs-note-text"><p>This setting is supported in AWS DMS versions 3.4.2 and higher.</p></div></div>
                            </td>
                        </tr>                        
                        <tr>
                            <td><a id="includeOpForFullLoad"></a><code class="code">IncludeOpForFullLoad</code></td>
                            <td>
                                <p>An optional parameter during a full load to write the INSERT
                                    operations to the comma-separated value (.csv) output files
                                    only.</p>
                                <p>For full load, records can only be inserted. By default (the
                                        <code class="code">false</code> setting), there is no information
                                    recorded in these output files for a full load to indicate that
                                    the rows were inserted at the source database. If
                                        <code class="code">IncludeOpForFullLoad</code> is set to
                                        <code class="code">true</code> or <code class="code">y</code>, the INSERT is recorded
                                    as an I annotation in the first field of the .csv file.</p>
                                <div class="awsdocs-note"><div class="awsdocs-note-title"><awsui-icon name="status-info" variant="link"></awsui-icon><h6>Note</h6></div><div class="awsdocs-note-text"><p>This parameter works together with
                                            <code class="code">CdcInsertsOnly</code>  or
                                            <code class="code">CdcInsertsAndUpdates</code> for output to .csv
                                        files only. For more information about how these parameters
                                        work together, see <a href="#CHAP_Target.S3.Configuring.InsertOps">Indicating source DB
                    operations in migrated S3 data</a>.</p></div></div>
                                <p>Default value: <code class="code">false</code></p>
                                <p>Valid values: <code class="code">true</code>, <code class="code">false</code>,
                                        <code class="code">y</code>, <code class="code">n</code></p>
                                <p>Example: <code class="code">--s3-settings '<span>{</span>"IncludeOpForFullLoad": true}'</code></p>
                            </td>
                        </tr>
                        <tr>
                            <td><code class="code">CompressionType</code></td>
                            <td>
                                <p>An optional parameter when set to <code class="code">GZIP</code> uses GZIP
                                    to compress the target .csv or .parquet files. When this
                                    parameter is set to the default, it leaves the files
                                    uncompressed.</p>
                                <p>Default value: <code class="code">NONE</code></p>
                                <p>Valid values: <code class="code">GZIP</code> or <code class="code">NONE</code></p>
                                <p>Example: <code class="code">--s3-settings '<span>{</span>"CompressionType": "GZIP"}'</code></p>
                            </td>
                        </tr>
                        <tr>
                            <td><code class="code">CsvDelimiter</code></td>
                            <td>
                                <p>The delimiter used to separate columns in .csv source files.
                                    The default is a comma (,).</p>
                                <p>Example: <code class="code">--s3-settings '<span>{</span>"CsvDelimiter": ","}'</code></p>
                            </td>
                        </tr>
                        <tr>
                            <td><code class="code">CsvRowDelimiter</code></td>
                            <td>
                                <p>The delimiter used to separate rows in the .csv source files.
                                    The default is a newline (\n).</p>
                                <p>Example: <code class="code">--s3-settings '<span>{</span>"CsvRowDelimiter": "\n"}'</code></p>
                            </td>
                        </tr>
                        <tr>
                            <td>
                                <p>
                                    <code class="code">MaxFileSize</code>
                                </p>
                            </td>
                            <td>
                                <p>A value that specifies the maximum size (in KB) of any .csv
                                    file to be created while migrating to an S3 target during full
                                    load.</p>
                                <p>Default value: 1,048,576 KB (1 GB)</p>
                                <p>Valid values: 1–1,048,576</p>
                                <p>Example: <code class="code">--s3-settings '<span>{</span>"MaxFileSize": 512}'</code></p>
                            </td>
                        </tr>
                        <tr>
                            <td><code class="code">Rfc4180</code></td>
                            <td>
                                <p>An optional parameter used to set behavior to comply with RFC
                                    for data migrated to Amazon S3 using .csv file format only. When this
                                    value is set to <code class="code">true</code> or <code class="code">y</code> using Amazon
                                    S3 as a target, if the data has quotation marks, commas, or newline
                                    characters in it, AWS DMS encloses the entire column with an
                                    additional pair of double quotation marks ("). Every quotation
                                    mark within the data is repeated twice. This formatting complies
                                    with RFC 4180.</p>
                                <p>Default value: <code class="code">true</code></p>
                                <p>Valid values: <code class="code">true</code>, <code class="code">false</code>,
                                        <code class="code">y</code>, <code class="code">n</code></p>
                                <p>Example: <code class="code">--s3-settings '<span>{</span>"Rfc4180": false}'</code></p>                            
                            </td>
                        </tr>
                        <tr>
                            <td><code class="code">EncryptionMode</code></td>
                            <td>
                                <p>The server-side encryption mode that you want to encrypt your
                                    .csv or .parquet object files copied to S3. The valid values are
                                        <code class="code">SSE_S3</code> (S3 server-side encryption) or
                                    <code class="code">SSE_KMS</code> (KMS key encryption). If you choose
                                        <code class="code">SSE_KMS</code>, set the
                                        <code class="code">ServerSideEncryptionKmsKeyId</code> parameter to the
                                    Amazon Resource Name (ARN) for the KMS key to be used for
                                    encryption.</p>
                                <div class="awsdocs-note"><div class="awsdocs-note-title"><awsui-icon name="status-info" variant="link"></awsui-icon><h6>Note</h6></div><div class="awsdocs-note-text"><p>You can also use the CLI <code class="code">modify-endpoint</code>
                                        command to change the value of the
                                            <code class="code">EncryptionMode</code> attribute for an existing
                                        endpoint from <code class="code">SSE_KMS</code> to <code class="code">SSE_S3</code>.
                                        But you can’t change the <code class="code">EncryptionMode</code> value
                                        from <code class="code">SSE_S3</code> to <code class="code">SSE_KMS</code>.</p></div></div>
                                <p>Default value: <code class="code">SSE_S3</code></p>
                                <p>Valid values: <code class="code">SSE_S3</code> or
                                    <code class="code">SSE_KMS</code></p>
                                <p>Example: <code class="code">--s3-settings '<span>{</span>"EncryptionMode": SSE_S3}'</code></p>
                            </td>
                        </tr>
                        <tr>
                            <td><code class="code">ServerSideEncryptionKmsKeyId</code></td>
                            <td>
                                <p>If you set <code class="code">EncryptionMode</code> to
                                    <code class="code">SSE_KMS</code>, set this parameter to the Amazon Resource
                                    Name (ARN) for the KMS key. You can find this ARN by selecting
                                    the key alias in the list of AWS KMS keys created for your
                                    account. When you create the key, you must associate specific
                                    policies and roles associated with this KMS key. For more
                                    information, see <a href="#CHAP_Target.S3.KMSKeys">Creating AWS KMS keys to encrypt Amazon S3 target
                    objects</a>.</p>
                                <p>Example: <code class="code">--s3-settings '<span>{</span>"ServerSideEncryptionKmsKeyId":"arn:aws:kms:us-east-1:111122223333:key/11a1a1a1-aaaa-9999-abab-2bbbbbb222a2"}'</code></p>                               
                               </td>
                        </tr>
                        <tr>
                            <td><code class="code">DataFormat</code></td>
                            <td>
                                <p>The output format for the files that AWS DMS uses to create S3
                                    objects. For Amazon S3 targets, AWS DMS supports either .csv or
                                    .parquet files. The .parquet files have a binary columnar
                                    storage format with efficient compression options and faster
                                    query performance. For more information about .parquet files,
                                    see <a href="https://parquet.apache.org/" rel="noopener noreferrer" target="_blank"><span>https://parquet.apache.org/</span><awsui-icon class="awsdocs-link-icon" name="external"></awsui-icon></a>.</p>
                                <p>Default value: <code class="code">csv</code></p>
                                <p>Valid values: <code class="code">csv</code> or <code class="code">parquet</code></p>
                                <p>Example: <code class="code">--s3-settings '<span>{</span>"DataFormat": "parquet"}'</code></p>
                            </td>
                        </tr>
                        <tr>
                            <td><code class="code">EncodingType</code></td>
                            <td>
                                <p>The Parquet encoding type. The encoding type options include
                                    the following:</p>
                                <div class="itemizedlist">
                                     
                                     
                                     
                                <ul class="itemizedlist"><li class="listitem">
                                        <p><code class="code">rle-dictionary</code> – This dictionary
                                            encoding uses a combination of bit-packing and
                                            run-length encoding to more efficiently store repeating
                                            values.</p>
                                    </li><li class="listitem">
                                        <p><code class="code">plain</code> – No encoding. </p>
                                    </li><li class="listitem">
                                        <p><code class="code">plain-dictionary</code> – This dictionary
                                            encoding builds a dictionary of values encountered in a
                                            given column. The dictionary is stored in a dictionary
                                            page for each column chunk.</p>
                                    </li></ul></div>
                                <p>Default value: <code class="code">rle-dictionary</code></p>
                                <p>Valid values: <code class="code">rle-dictionary</code>, <code class="code">plain</code>,
                                    or <code class="code">plain-dictionary</code></p>
                                <p>Example: <code class="code">--s3-settings '<span>{</span>"EncodingType": "plain-dictionary"}'</code></p>
                            </td>
                        </tr>
                        <tr>
                            <td><code class="code">DictPageSizeLimit</code></td>
                            <td>
                                <p>The maximum allowed size, in bytes, for a dictionary page in a
                                    .parquet file. If a dictionary page exceeds this value, the page
                                    uses plain encoding.</p>
                                <p>Default value: 1,024,000 (1 MB)</p>
                                <p>Valid values: Any valid integer value</p>
                                <p>Example: <code class="code">--s3-settings '<span>{</span>"DictPageSizeLimit": 2,048,000}'</code></p>
                            </td>
                        </tr>
                        <tr>
                            <td><code class="code">RowGroupLength</code></td>
                            <td>
                                <p>The number of rows in one row group of a .parquet file.</p>
                                <p>Default value: 10,024 (10 KB)</p>
                                <p>Valid values: Any valid integer</p>
                                <p>Example: <code class="code">--s3-settings '<span>{</span>"RowGroupLength": 20,048}'</code></p>
                            </td>
                        </tr>
                        <tr>
                            <td><code class="code">DataPageSize</code></td>
                            <td>
                                <p>The maximum allowed size, in bytes, for a data page in a
                                    .parquet file.</p>
                                <p>Default value: 1,024,000 (1 MB)</p>
                                <p>Valid values: Any valid integer</p>
                                <p>Example: <code class="code">--s3-settings '<span>{</span>"DataPageSize": 2,048,000}'</code></p>
                            </td>
                        </tr>
                        <tr>
                            <td><code class="code">ParquetVersion</code></td>
                            <td>
                                <p>The version of the .parquet file format.</p>
                                <p>Default value: <code class="code">PARQUET_1_0</code></p>
                                <p>Valid values: <code class="code">PARQUET_1_0</code> or
                                        <code class="code">PARQUET_2_0</code></p>
                                <p>Example: <code class="code">--s3-settings '<span>{</span>"ParquetVersion": "PARQUET_2_0"}'</code></p>
                            </td>
                        </tr>
                        <tr>
                            <td><code class="code">EnableStatistics</code></td>
                            <td>
                                <p>Set to <code class="code">true</code> or <code class="code">y</code> to enable
                                    statistics about .parquet file pages and row groups.</p>
                                <p>Default value: <code class="code">true</code></p>
                                <p>Valid values: <code class="code">true</code>, <code class="code">false</code>,
                                        <code class="code">y</code>, <code class="code">n</code></p>
                                <p>Example: <code class="code">--s3-settings '<span>{</span>"EnableStatistics": false}'</code></p>                                
                            </td>
                        </tr>
                        <tr>
                            <td><a id="timestampColumnName"></a><code class="code">TimestampColumnName</code></td>
                            <td>
                                <p>An optional parameter to include a timestamp column in the S3
                                    target endpoint data.</p>
                                <p>AWS DMS includes an additional <code class="code">STRING</code> column in the
                                    .csv or .parquet object files of your migrated data when you set
                                        <code class="code">TimestampColumnName</code> to a non blank value.</p>
                                <p>For a full load, each row of this timestamp column contains a
                                    timestamp for when the data was transferred from the source to
                                    the target by DMS. </p>
                                <p>For a CDC load, each row of the timestamp column contains the
                                    timestamp for the commit of that row in the source
                                    database.</p>
                                <p>The string format for this timestamp column value is
                                        <code class="code">yyyy-MM-dd HH:mm:ss.SSSSSS</code>. By default, the
                                    precision of this value is in microseconds. For a CDC load, the
                                    rounding of the precision depends on the commit timestamp
                                    supported by DMS for the source database.</p>
                                <p>When the <code class="code">AddColumnName</code> parameter is set to
                                        <code class="code">true</code>, DMS also includes the name for the
                                    timestamp column that you set as the non blank value of
                                        <code class="code">TimestampColumnName</code>.</p>
                                <p>Example: <code class="code">--s3-settings '<span>{</span>"TimestampColumnName": "TIMESTAMP"}'</code></p> 
                            </td>
                        </tr>
                        <tr>
                            <td><a id="useTaskStartTimeForFullLoadTimestamp"></a><code class="code">UseTaskStartTimeForFullLoadTimestamp</code></td>
                            <td>
                                <p>When set to <code class="code">true</code>, this parameter uses the task start time as the timestamp column value 
                                    instead of the time data is written to target. For full load, when <code class="code">UseTaskStartTimeForFullLoadTimestamp</code> 
                                    is set to <code class="code">true</code>, each row of the timestamp column contains the task start time.  
                                    For CDC loads, each row of the timestamp column contains the transaction commit time.</p>
                                <p>When <code class="code">UseTaskStartTimeForFullLoadTimestamp</code> is set to <code class="code">false</code>, the 
                                    full load timestamp in the timestamp column increments with the time data arrives at the target.</p>
                                <p>Default value: <code class="code">false</code></p>
                                <p>Valid values: <code class="code">true</code>, <code class="code">false</code></p>
                                <p>Example: <code class="code">--s3-settings '<span>{</span>"UseTaskStartTimeForFullLoadTimestamp": true}'</code></p>
                                
                                <p><code class="code">UseTaskStartTimeForFullLoadTimestamp: true</code> helps
                                    make the S3 target <code class="code">TimestampColumnName</code> for a full
                                    load sortable with <code class="code">TimestampColumnName</code> for a CDC
                                    load.</p>

                            </td>
                        </tr>                        
                        <tr>
                            <td><a id="parquetTimestampInMillisecond"></a><code class="code">ParquetTimestampInMillisecond</code></td>
                            <td>
                                <p>An optional parameter that specifies the precision of any
                                        <code class="code">TIMESTAMP</code> column values written to an S3 object
                                    file in .parquet format.</p>
                                <p>When this attribute is set to <code class="code">true</code> or
                                        <code class="code">y</code>, AWS DMS writes all <code class="code">TIMESTAMP</code>
                                    columns in a .parquet formatted file with millisecond precision.
                                    Otherwise, DMS writes them with microsecond precision.</p>
                                <p>Currently, Amazon Athena and AWS Glue can handle only
                                    millisecond precision for <code class="code">TIMESTAMP</code> values. Set
                                    this attribute to true for .parquet formatted S3 endpoint object
                                    files only if you plan to query or process the data with Athena
                                    or AWS Glue.</p>
                                <div class="awsdocs-note"><div class="awsdocs-note-title"><awsui-icon name="status-info" variant="link"></awsui-icon><h6>Note</h6></div><div class="awsdocs-note-text"><div class="itemizedlist">
                                         
                                         
                                    <ul class="itemizedlist"><li class="listitem">
                                            <p>AWS DMS writes any <code class="code">TIMESTAMP</code> column
                                                values written to an S3 file in .csv format with
                                                microsecond precision.</p>
                                        </li><li class="listitem">
                                            <p>The setting of this attribute has no effect on the
                                                string format of the timestamp column value inserted
                                                by setting the <code class="code">TimestampColumnName</code>
                                                attribute.</p>
                                        </li></ul></div></div></div>
                                <p>Default value: <code class="code">false</code></p>
                                <p>Valid values: <code class="code">true</code>, <code class="code">false</code>,
                                        <code class="code">y</code>, <code class="code">n</code></p>
                                <p>Example: <code class="code">--s3-settings '<span>{</span>"ParquetTimestampInMillisecond": true}'</code></p>
                            </td>
                        </tr>
                        <tr>
                            <td><code class="code">GlueCatalogGeneration</code></td>
                            <td>
                                <p>To generate an AWS Glue Data Catalog, set this endpoint setting to <code class="code">true</code>.</p>
                                <p>Default value: <code class="code">false</code></p>
                                <p>Valid values: <code class="code">true</code>, <code class="code">false</code>,</p>
                                <p>Example: <code class="code">--s3-settings '<span>{</span>"GlueCatalogGeneration": true}'</code></p>
                                <p><b>Note: </b>Don't use
                                    <code class="code">GlueCatalogGeneration</code> with
                                    <code class="code">PreserveTransactions</code> and
                                <code class="code">CdcPath</code>.</p>                                
                            </td>                             
                        </tr>
                    </table></div></div>
         
        <h2 id="CHAP_Target.S3.GlueCatalog">Using AWS Glue Data Catalog with an Amazon S3
                target for AWS DMS</h2>
        <p>AWS Glue is a service that provides simple ways to categorize data, and consists of a
            metadata repository known as AWS Glue Data Catalog. You can integrate AWS Glue Data Catalog with your Amazon S3
            target endpoint and query Amazon S3 data through other AWS services such as Amazon Athena.
            Amazon Redshift works with AWS Glue but AWS DMS doesn't support that as a pre-built option. 
        </p>
        
        <p>To generate the data catalog, set the <code class="code">GlueCatalogGeneration</code> endpoint 
            setting to <code class="code">true</code>, as shown in the following AWS CLI example.</p>
        <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="">aws dms create-endpoint --endpoint-identifier s3-target-endpoint 
            --engine-name s3 --endpoint-type target--s3-settings '<span>{</span>"ServiceAccessRoleArn": 
            "your-service-access-ARN", "BucketFolder": "your-bucket-folder", "BucketName": 
            "your-bucket-name", "DataFormat": "parquet", "GlueCatalogGeneration": true}'</code></pre>
        
        <p>For a Full load replication task that includes <code class="code">csv</code> type data, set 
            <code class="code">IncludeOpForFullLoad</code> to <code class="code">true</code>.</p>
        
        <p>Don't use <code class="code">GlueCatalogGeneration</code> with
                <code class="code">PreserveTransactions</code> and <code class="code">CdcPath</code>. The AWS Glue crawler
            can't reconcile the different schemas of files stored under the specified
            <code class="code">CdcPath</code>.</p>
        
        <p>For Amazon Athena to index your Amazon S3 data, and for you to query your data using standard
            SQL queries through Amazon Athena, the migration task must have the following set of permissions.</p>
        <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class=""><span>{</span>
    "Version": "2012-10-17", 
    "Statement": [ 
        <span>{</span>
            "Effect": "Allow", 
            "Action": [
                "s3:GetBucketLocation", 
                "s3:GetObject",
                "s3:ListBucket", 
                "s3:ListBucketMultipartUploads", 
                "s3:ListMultipartUploadParts", 
                "s3:AbortMultipartUpload" 
            ], 
            "Resource": [
                "arn:aws:s3:::bucket123", 
                "arn:aws:s3:::bucket123/*" 
            ]
        },
        <span>{</span>
            "Effect": "Allow", 
            "Action": [ 
                "glue:CreateDatabase", 
                "glue:GetDatabase", 
                "glue:CreateTable", 
                "glue:DeleteTable", 
                "glue:UpdateTable", 
                "glue:GetTable", 
                "glue:BatchCreatePartition", 
                "glue:CreatePartition", 
                "glue:UpdatePartition", 
                "glue:GetPartition", 
                "glue:GetPartitions", 
                "glue:BatchGetPartition"
            ], 
            "Resource": [
                "arn:aws:glue:*:111122223333:catalog", 
                "arn:aws:glue:*:111122223333:database/*", 
                "arn:aws:glue:*:111122223333:table/*" 
            ]
        }, 
        <span>{</span>
            "Effect": "Allow",
            "Action": [
                "athena:StartQueryExecution",
                "athena:GetQueryExecution", 
                "athena:CreateWorkGroup"
            ],
            "Resource": "arn:aws:athena:*:111122223333:workgroup/glue_catalog_generation_for_task_*"
        }
    ]
}
</code></pre>

        <div class="itemizedlist">
            <h6>References</h6>
             
                         
        <ul class="itemizedlist"><li class="listitem">
                <p>For more information about AWS Glue, see 
                <a href="https://docs.aws.amazon.com/glue/latest/dg/components-key-concepts.html">Concepts</a> in the <em>AWS Glue Developer Guide</em>
                .</p>
            </li><li class="listitem">
                <p>For more information about AWS Glue Data Catalog see 
                    <a href="https://docs.aws.amazon.com/glue/latest/dg/components-overview.html">Components</a> in the <em>AWS Glue Developer Guide</em>
                .</p>
            </li></ul></div>
     
            <h2 id="CHAP_Target.S3.EndpointSettings">Using data encryption, parquet files, and CDC on your Amazon S3
                target</h2>

            <p>You can use S3 target endpoint settings to configure the following:</p>
            <div class="itemizedlist">
                 
                 
                 
                 
            <ul class="itemizedlist"><li class="listitem">
                    <p>A custom KMS key to encrypt your S3 target objects.</p>
                </li><li class="listitem">
                    <p>Parquet files as the storage format for S3 target objects.</p>
                </li><li class="listitem">
                    <p>Change data capture (CDC) including transaction order on the S3
                        target.</p>
                </li><li class="listitem">
                    <p>Integrate AWS Glue Data Catalog with your Amazon S3 target endpoint and query Amazon S3 data
                    through other services such as Amazon Athena.</p>
                </li></ul></div>
             
                <h3 id="CHAP_Target.S3.EndpointSettings.KMSkeys">AWS KMS key settings for
                        data encryption</h3>
                <p>The following examples show configuring a custom KMS key to encrypt your S3
                    target objects. To start, you might run the following
                        <code class="code">create-endpoint</code> CLI command.</p>
                <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="nohighlight">aws dms create-endpoint --endpoint-identifier s3-target-endpoint --engine-name s3 --endpoint-type target 
--s3-settings '<span>{</span>"ServiceAccessRoleArn": "<code class="replaceable">your-service-access-ARN</code>", "CsvRowDelimiter": "\n", 
"CsvDelimiter": ",", "BucketFolder": "<code class="replaceable">your-bucket-folder</code>", 
"BucketName": "<code class="replaceable">your-bucket-name</code>", 
"EncryptionMode": "SSE_KMS", 
"ServerSideEncryptionKmsKeyId": "arn:aws:kms:us-east-1:111122223333:key/72abb6fb-1e49-4ac1-9aed-c803dfcc0480"}'</code></pre>
                <p>Here, the JSON object specified by <code class="code">--s3-settings</code> option defines
                    two parameters. One is an <code class="code">EncryptionMode</code> parameter with the value
                        <code class="code">SSE_KMS</code>. The other is an
                        <code class="code">ServerSideEncryptionKmsKeyId</code> parameter with the value of
                        <code class="code">arn:aws:kms:us-east-1:111122223333:key/72abb6fb-1e49-4ac1-9aed-c803dfcc0480</code>.
                    This value is an Amazon Resource Name (ARN) for your custom KMS key. For an S3
                    target, you also specify additional settings. These identify the server access
                    role, provide delimiters for the default CSV object storage format, and give the
                    bucket location and name to store S3 target objects.</p>
                <p>By default, S3 data encryption occurs using S3 server-side encryption. For the
                    previous example's S3 target, this is also equivalent to specifying its
                    endpoint settings as in the following example.</p>
                <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="nohighlight">aws dms create-endpoint --endpoint-identifier s3-target-endpoint --engine-name s3 --endpoint-type target
--s3-settings '<span>{</span>"ServiceAccessRoleArn": "<code class="replaceable">your-service-access-ARN</code>", "CsvRowDelimiter": "\n", 
"CsvDelimiter": ",", "BucketFolder": "<code class="replaceable">your-bucket-folder</code>", 
"BucketName": "<code class="replaceable">your-bucket-name</code>", 
"EncryptionMode": "SSE_S3"}'</code></pre>
                <p>For more information about working with S3 server-side encryption, see <a href="https://docs.aws.amazon.com/AmazonS3/latest/dev/serv-side-encryption.html">Protecting data using server-side encryption</a>.</p>
                <div class="awsdocs-note"><div class="awsdocs-note-title"><awsui-icon name="status-info" variant="link"></awsui-icon><h6>Note</h6></div><div class="awsdocs-note-text"><p>You can also use the CLI <code class="code">modify-endpoint</code> command to change
                        the value of the <code class="code">EncryptionMode</code> parameter for an existing
                        endpoint from <code class="code">SSE_KMS</code> to <code class="code">SSE_S3</code>. But you can’t
                        change the <code class="code">EncryptionMode</code> value from <code class="code">SSE_S3</code> to
                            <code class="code">SSE_KMS</code>.</p></div></div>               
             
             
                <h3 id="CHAP_Target.S3.EndpointSettings.Parquet">Settings for using .parquet files to
                        store S3 target objects</h3>
                <p>The default format for creating S3 target objects is .csv files. The following
                    examples show some endpoint settings for specifying .parquet files as the format
                    for creating S3 target objects. You can specify the .parquet files format with
                    all the defaults, as in the following example.</p>
                <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="nohighlight">aws dms create-endpoint --endpoint-identifier s3-target-endpoint --engine-name s3 --endpoint-type target 
--s3-settings '<span>{</span>"ServiceAccessRoleArn": "<code class="replaceable">your-service-access-ARN</code>", "DataFormat": "parquet"}'</code></pre>
                <p>Here, the <code class="code">DataFormat</code> parameter is set to <code class="code">parquet</code> to
                    enable the format with all the S3 defaults. These defaults include a dictionary
                    encoding (<code class="code">"EncodingType: "rle-dictionary"</code>) that uses a combination
                    of bit-packing and run-length encoding to more efficiently store repeating
                    values.</p>
                <p>You can add additional settings for options other than the defaults as in the
                    following example.</p>
                <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="">aws dms create-endpoint --endpoint-identifier s3-target-endpoint --engine-name s3 --endpoint-type target
--s3-settings '<span>{</span>"ServiceAccessRoleArn": "your-service-access-ARN", "BucketFolder": "your-bucket-folder",
"BucketName": "your-bucket-name", "CompressionType": "GZIP", "DataFormat": "parquet", "EncodingType: "plain-dictionary", "DictPageSizeLimit": 3,072,000,
"EnableStatistics": false }'</code></pre>
                <p>Here, in addition to parameters for several standard S3 bucket options and the
                        <code class="code">DataFormat</code> parameter, the following additional .parquet file
                    parameters are set:</p>
                <div class="itemizedlist">
                     
                     
                     
                <ul class="itemizedlist"><li class="listitem">
                        <p><code class="code">EncodingType</code> – Set to a dictionary encoding
                                (<code class="code">plain-dictionary</code>) that stores values encountered in
                            each column in a per-column chunk of the dictionary page.</p>
                    </li><li class="listitem">
                        <p><code class="code">DictPageSizeLimit</code> – Set to a maximum dictionary
                            page size of 3 MB.</p>
                    </li><li class="listitem">
                        <p><code class="code">EnableStatistics</code> – Disables the default that
                            enables the collection of statistics about Parquet file pages and row
                            groups.</p>
                    </li></ul></div>
             
             
                <h3 id="CHAP_Target.S3.EndpointSettings.CdcPath">Capturing data changes
                        (CDC) including transaction order on the S3 target</h3>
                <p>By default when AWS DMS runs a CDC task, it stores all the row changes logged in
                    your source database (or databases) in one or more files for each table. Each
                    set of files containing changes for the same table reside in a single target
                    directory associated with that table. AWS DMS creates as many target directories
                    as database tables migrated to the Amazon S3 target endpoint. The files are stored on
                    the S3 target in these directories without regard to transaction order. For more
                    information on the file naming conventions, data contents, and format, see <a href="./CHAP_Target.S3.html">Using Amazon S3 as a target for AWS Database Migration Service</a>.</p>
                <p>To capture source database changes in a manner that also captures the
                transaction order, you can specify S3 endpoint settings that direct AWS DMS to store
                the row changes for <em>all</em> database tables in one or more .csv
                files created depending on transaction size. These .csv <em>transaction
                    files</em> contain all row changes listed sequentially in transaction
                order for all tables involved in each transaction. These transaction files reside
                together in a single <em>transaction directory</em> that you also
                specify on the S3 target. In each transaction file, the transaction operation and
                the identity of the database and source table for each row change is stored as part
                of the row data as follows. </p>
                <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="nohighlight"><code class="replaceable">operation</code>,<code class="replaceable">table_name</code>,<code class="replaceable">database_schema_name</code>,<code class="replaceable">field_value</code>,...</code></pre>
                <p>Here, <code class="code"><code class="replaceable">operation</code></code> is the transaction
                    operation on the changed row, <code class="code"><code class="replaceable">table_name</code></code>
                    is the name of the database table where the row is changed,
                            <code class="code"><code class="replaceable">database_schema_name</code></code> is the name
                    of the database schema where the table resides, and
                            <code class="code"><code class="replaceable">field_value</code></code> is the first of one
                    or more field values that specify the data for the row.</p>
                <p>The example following of a transaction file shows changed rows for one or more
                    transactions that involve two tables.</p>
                <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="">I,Names_03cdcad11a,rdsTempsdb,13,Daniel
U,Names_03cdcad11a,rdsTempsdb,23,Kathy
D,Names_03cdcad11a,rdsTempsdb,13,Cathy
I,Names_6d152ce62d,rdsTempsdb,15,Jane
I,Names_6d152ce62d,rdsTempsdb,24,Chris
I,Names_03cdcad11a,rdsTempsdb,16,Mike</code></pre>
                <p>Here, the transaction operation on each row is indicated by <code class="code">I</code>
                    (insert), <code class="code">U</code> (update), or <code class="code">D</code> (delete) in the first
                    column. The table name is the second column value (for example,
                        <code class="code">Names_03cdcad11a</code>). The name of the database schema is the value
                    of the third column (for example, <code class="code">rdsTempsdb</code>). And the remaining
                    columns are populated with your own row data (for example,
                        <code class="code">13,Daniel</code>).</p>
                <p>In addition, AWS DMS names the transaction files it creates on the Amazon S3 target
                    using a time stamp according to the following naming convention.</p>
                <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="nohighlight">CDC_TXN-<code class="replaceable">timestamp</code>.csv</code></pre>
                <p>Here, <code class="code"><code class="replaceable">timestamp</code></code> is the time when the
                    transaction file was created, as in the following example. </p>
                <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="">CDC_TXN-20201117153046033.csv</code></pre>
                <p>This time stamp in the file name ensures that the transaction files are created
                    and listed in transaction order when you list them in their transaction
                    directory.</p>
                <div class="awsdocs-note"><div class="awsdocs-note-title"><awsui-icon name="status-info" variant="link"></awsui-icon><h6>Note</h6></div><div class="awsdocs-note-text"><p>When capturing data changes in transaction order, AWS DMS always stores the
                        row changes in .csv files regardless of the value of the
                            <code class="code">DataFormat</code> S3 setting on the target. AWS DMS doesn't save
                        data changes in transaction order using .parquet files.</p></div></div>
                
                <p>To control the frequency of writes to an Amazon S3 target during a data replication 
                    task, you can configure the <code class="code">CdcMaxBatchInterval</code> and <code class="code">CdcMinFileSize</code> settings. 
                    This can result in better performance when analyzing the data without any 
                    additional overhead operations.  For more information, see <a href="#CHAP_Target.S3.Configuring">Endpoint settings when using
                    Amazon S3 as a target for AWS DMS</a>
                </p> 
                
                <div class="procedure"><h6>To tell AWS DMS to store all row changes in transaction order</h6><ol><li>
                        <p>Set the <code class="code">PreserveTransactions</code> S3 setting on the target to
                                <code class="code">true</code>.</p>
                    </li><li>
                        <p>Set the <code class="code">CdcPath</code> S3 setting on the target to a relative
                            folder path where you want AWS DMS to store the .csv transaction
                            files.</p>
                        <p>AWS DMS creates this path either under the default S3 target bucket and
                            working directory or under the bucket and bucket folder that you specify
                            using the <code class="code">BucketName</code> and <code class="code">BucketFolder</code> S3
                            settings on the target.</p>
                    </li></ol></div>                          
             
         
            <h2 id="CHAP_Target.S3.Configuring.InsertOps">Indicating source DB
                    operations in migrated S3 data</h2>
            <p>When AWS DMS migrates records to an S3 target, it can create an additional field
                in each migrated record. This additional field indicates the operation applied
                to the record at the source database. How AWS DMS creates and sets this first field
                depends on the migration task type and settings of <code class="code">includeOpForFullLoad</code>,
                <code class="code">cdcInsertsOnly</code>, and <code class="code">cdcInsertsAndUpdates</code>.</p>
            <p>For a full load when <code class="code">includeOpForFullLoad</code> is <code class="code">true</code>, 
                AWS DMS always creates an additional first field in each .csv record. This field 
                contains the letter I (INSERT) to indicate that the row was inserted at the source 
                database. For a CDC load when <code class="code">cdcInsertsOnly</code> is <code class="code">false</code> 
                (the default), AWS DMS also always creates an additional first field in each .csv 
                or .parquet record. This field contains the letter I (INSERT), U (UPDATE), 
                or D (DELETE) to indicate whether the row was inserted, updated, or deleted 
                at the source database.</p>
            <p>In the following table, you can see how the settings of the 
                <code class="code">includeOpForFullLoad</code> and <code class="code">cdcInsertsOnly</code> attributes 
                work together to affect the setting of migrated records.</p>
                <div class="table-container"><div class="table-contents"><table id="w350aac29c13c23c53b9"><thead>
                            <tr>
                                <th colspan="2">With these parameter
                                    settings</th>
                                <th colspan="2">DMS sets target records as follows
                                    for .csv and .parquet output </th>
                            </tr>
                            <tr>
                                <th>includeOpForFullLoad</th>
                                <th>cdcInsertsOnly</th>
                                <th>For full load</th>
                                <th>For CDC load</th>
                            </tr>
                        </thead>
                            <tr>
                                <td><code class="code">true</code></td>
                                <td><code class="code">true</code></td>
                                <td>Added first field value set to <code class="code">I</code></td>
                                <td>Added first field value set to <code class="code">I</code></td>
                            </tr>
                            <tr>
                                <td><code class="code">false</code></td>
                                <td><code class="code">false</code></td>
                                <td>No added field</td>
                                <td>Added first field value set to <code class="code">I</code>,
                                    <code class="code">U</code>, or <code class="code">D</code></td>
                            </tr>
                            <tr>
                                <td><code class="code">false</code></td>
                                <td><code class="code">true</code></td>
                                <td>No added field</td>
                                <td>No added field</td>
                            </tr>
                            <tr>
                                <td><code class="code">true</code></td>
                                <td><code class="code">false</code></td>
                                <td>Added first field value set to <code class="code">I</code></td>
                                <td>Added first field value set to <code class="code">I</code>,
                                    <code class="code">U</code>, or <code class="code">D</code></td>
                            </tr>
                        </table></div></div>

                <p>When <code class="code">includeOpForFullLoad</code> and <code class="code">cdcInsertsOnly</code> are
                    set to the same value, the target records are set according to the attribute
                    that controls record settings for the current migration type. That attribute is
                        <code class="code">includeOpForFullLoad</code> for full load and
                        <code class="code">cdcInsertsOnly</code> for CDC load.</p>
                        <p>When <code class="code">includeOpForFullLoad</code> and <code class="code">cdcInsertsOnly</code>
                    are set to different values, AWS DMS makes the target record settings consistent
                    for both CDC and full load. It does this by making the record settings for a CDC
                    load conform to the record settings for any earlier full load specified by
                        <code class="code">includeOpForFullLoad</code>. </p>
                <p>In other words, suppose that a full load is set to add a first field to
                    indicate an inserted record. In this case, a following CDC load is set to add a
                    first field that indicates an inserted, updated, or deleted record as
                    appropriate at the source. In contrast, suppose that a full load is set to
                        <em>not</em> add a first field to indicate an inserted record.
                    In this case, a CDC load is also set to not add a first field to each record
                    regardless of its corresponding record operation at the source.</p>

                <p>Similarly, how DMS creates and sets an additional first field depends on the
                    settings of <code class="code">includeOpForFullLoad</code> and
                        <code class="code">cdcInsertsAndUpdates</code>. In the following table, you can see how
                    the settings of the <code class="code">includeOpForFullLoad</code> and
                        <code class="code">cdcInsertsAndUpdates</code> attributes work together to affect the
                    setting of migrated records in this format. </p>
                <div class="table-container"><div class="table-contents"><table id="w350aac29c13c23c53c19"><thead>
                            <tr>
                                <th colspan="2">With these parameter
                                    settings</th>
                                <th colspan="2">DMS sets target records as follows
                                    for .csv output </th>
                            </tr>
                            <tr>
                                <th>includeOpForFullLoad</th>
                                <th>cdcInsertsAndUpdates</th>
                                <th>For full load</th>
                                <th>For CDC load</th>
                            </tr>
                        </thead>
                            <tr>
                                <td><code class="code">true</code></td>
                                <td><code class="code">true</code></td>
                                <td>Added first field value set to <code class="code">I</code></td>
                                <td>Added first field value set to <code class="code">I</code> or <code class="code">U</code></td>
                            </tr>
                            <tr>
                                <td><code class="code">false</code></td>
                                <td><code class="code">false</code></td>
                                <td>No added field</td>
                                <td>Added first field value set to <code class="code">I</code>,
                                    <code class="code">U</code>, or <code class="code">D</code></td>
                            </tr>
                            <tr>
                                <td><code class="code">false</code></td>
                                <td><code class="code">true</code></td>
                                <td>No added field</td>
                                <td>Added first field value set to <code class="code">I</code> or <code class="code">U</code></td>
                            </tr>
                            <tr>
                                <td><code class="code">true</code></td>
                                <td><code class="code">false</code></td>
                                <td>Added first field value set to <code class="code">I</code></td>
                                <td>Added first field value set to <code class="code">I</code>,
                                    <code class="code">U</code>, or <code class="code">D</code></td>
                            </tr>
                        </table></div></div> 
         
                <h2 id="CHAP_Target.S3.DataTypes">Target data types for S3
                    Parquet</h2>
                
                <p>The following table shows the Parquet target data types that are supported
                when using AWS DMS and the default mapping from AWS DMS data types.</p>
                <p>For additional information about AWS DMS data types, see <a href="./CHAP_Reference.DataTypes.html">Data types for AWS Database Migration Service</a>.</p>
            
            <div class="table-container"><div class="table-contents"><table id="w350aac29c13c23c55b7"><thead>
                        <tr>
                            <th>
                                <p>AWS DMS data type</p>
                            </th>
                            <th>
                                <p>S3 parquet data type </p>
                            </th>
                        </tr>
                    </thead>
                        <tr>
                            <td><code class="code">BYTES</code></td>
                            <td><code class="code">BINARY</code></td>
                        </tr>
                        <tr>
                            <td><code class="code">DATE</code></td>
                            <td><code class="code">DATE32</code></td>
                        </tr>
                        <tr>
                            <td><code class="code">TIME</code></td>
                            <td><code class="code">TIME32</code></td>
                        </tr>
                        <tr>
                            <td><code class="code">DATETIME</code></td>
                            <td><code class="code">TIMESTAMP</code></td>
                        </tr>
                        <tr>
                            <td><code class="code">INT1</code></td>
                            <td><code class="code">INT8</code></td>
                        </tr>
                        <tr>
                            <td><code class="code">INT2</code></td>
                            <td><code class="code">INT16</code></td>
                        </tr>
                        <tr>
                            <td><code class="code">INT4</code></td>
                            <td><code class="code">INT32</code></td>
                        </tr>
                        <tr>
                            <td><code class="code">INT8</code></td>
                            <td><code class="code">INT64</code></td>
                        </tr>
                        <tr>
                            <td><code class="code">NUMERIC</code></td>
                            <td><code class="code">DECIMAL</code></td>
                        </tr>
                        <tr>
                            <td><code class="code">REAL4</code></td>
                            <td><code class="code">FLOAT</code></td>
                        </tr>
                        <tr>
                            <td><code class="code">REAL8</code></td>
                            <td><code class="code">DOUBLE</code></td>
                        </tr>
                        <tr>
                            <td><code class="code">STRING</code></td>
                            <td><code class="code">STRING</code></td>
                        </tr>
                        <tr>
                            <td><code class="code">UINT1</code></td>
                            <td><code class="code">UINT8</code></td>
                        </tr>
                        <tr>
                            <td><code class="code">UINT2</code></td>
                            <td><code class="code">UINT16</code></td>
                        </tr>
                        <tr>
                            <td><code class="code">UINT4</code></td>
                            <td><code class="code">UINT32</code></td>
                        </tr>
                        <tr>
                            <td><code class="code">UINT8</code></td>
                            <td><code class="code">UINT64</code></td>
                        </tr>
                        <tr>
                            <td><code class="code">WSTRING</code></td>
                            <td><code class="code">STRING</code></td>
                        </tr>
                        <tr>
                            <td><code class="code">BLOB</code></td>
                            <td><code class="code">BINARY</code></td>
                        </tr>
                        <tr>
                            <td><code class="code">NCLOB</code></td>
                            <td><code class="code">STRING</code></td>
                        </tr>
                        <tr>
                            <td><code class="code">CLOB</code></td>
                            <td><code class="code">STRING</code></td>
                        </tr>
                        <tr>
                            <td><code class="code">BOOLEAN</code></td>
                            <td><code class="code">BOOL</code></td>
                        </tr>
                    </table></div></div>
            
            
        <awsdocs-copyright class="copyright-print"></awsdocs-copyright><awsdocs-thumb-feedback right-edge="{{$ctrl.thumbFeedbackRightEdge}}"></awsdocs-thumb-feedback></div><noscript><div><div><div><div id="js_error_message"><p><img src="https://d1ge0kk1l5kms0.cloudfront.net/images/G/01/webservices/console/warning.png" alt="Warning" /> <strong>Javascript is disabled or is unavailable in your browser.</strong></p><p>To use the Amazon Web Services Documentation, Javascript must be enabled. Please refer to your browser's Help pages for instructions.</p></div></div></div></div></noscript><div id="main-col-footer" class="awsui-util-font-size-0"><div id="doc-conventions"><a target="_top" href="/general/latest/gr/docconventions.html">Document Conventions</a></div><div class="prev-next"><div id="previous" class="prev-link" accesskey="p" href="./CHAP_Target.SAP.html">Using SAP ASE as a target</div><div id="next" class="next-link" accesskey="n" href="./CHAP_Target.DynamoDB.html">Using Amazon DynamoDB as a target</div></div></div><awsdocs-page-utilities></awsdocs-page-utilities></div><div id="quick-feedback-yes" style="display: none;"><div class="title">Did this page help you? - Yes</div><div class="content"><p>Thanks for letting us know we're doing a good job!</p><p>If you've got a moment, please tell us what we did right so we can do more of it.</p><p><awsui-button id="fblink" rel="noopener noreferrer" target="_blank" text="Feedback" click="linkClick($event)" href="https://docs.aws.amazon.com/forms/aws-doc-feedback?hidden_service_name=DMS&amp;topic_url=https://docs.aws.amazon.com/en_us/dms/latest/userguide/CHAP_Target.S3.html"></awsui-button></p></div></div><div id="quick-feedback-no" style="display: none;"><div class="title">Did this page help you? - No</div><div class="content"><p>Thanks for letting us know this page needs work. We're sorry we let you down.</p><p>If you've got a moment, please tell us how we can make the documentation better.</p><p><awsui-button id="fblink" rel="noopener noreferrer" target="_blank" text="Feedback" click="linkClick($event)" href="https://docs.aws.amazon.com/forms/aws-doc-feedback?hidden_service_name=DMS&amp;topic_url=https://docs.aws.amazon.com/en_us/dms/latest/userguide/CHAP_Target.S3.html"></awsui-button></p></div></div></div></body></div></awsdocs-view><div class="page-loading-indicator" id="page-loading-indicator"><awsui-spinner size="large"></awsui-spinner></div></div><div id="tools-panel" dom-region="tools"><awsdocs-tools-panel id="awsdocs-tools-panel"></awsdocs-tools-panel></div></awsui-app-layout><awsdocs-cookie-banner class="doc-cookie-banner"></awsdocs-cookie-banner></div></body></html>